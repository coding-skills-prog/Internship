{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1). Scrape the details of most viewed videos on YouTube from Wikipedia.\n",
    "\n",
    "Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\n",
    "\n",
    "You need to find following details:\n",
    "\n",
    "A) Rank\n",
    "\n",
    "B) Name\n",
    "\n",
    "C) Artist\n",
    "\n",
    "D) Upload date\n",
    "\n",
    "E) Views\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#impoerting required libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connecting to a webdriver\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#site url\n",
    "url = 'https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(driver.page_source,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '',\n",
       " '1.',\n",
       " '\"Baby Shark Dance\"[3]',\n",
       " \"Pinkfong Baby Shark - Kids' Songs & Stories\",\n",
       " '10.23',\n",
       " 'June 17, 2016',\n",
       " '[B]',\n",
       " '',\n",
       " '',\n",
       " '2.',\n",
       " '\"Despacito\"[6]',\n",
       " 'Luis Fonsi',\n",
       " '7.75',\n",
       " 'January 12, 2017',\n",
       " '[C]',\n",
       " '',\n",
       " '',\n",
       " '3.',\n",
       " '\"Johny Johny Yes Papa\"[12]']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now getting whole table source data which is having a class of 'wikitable sortable jquery-tablesorter'\n",
    "\n",
    "result = soup.find('table',{'class':'wikitable sortable jquery-tablesorter'})\n",
    "\n",
    "#getting a body of table \n",
    "a = result.find('tbody')\n",
    "a_new = a.text.split(\"\\n\")\n",
    "\n",
    "a_new[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So,we can see that each youtube video contents having first 2 elements as empty strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1.',\n",
       " '\"Baby Shark Dance\"[3]',\n",
       " \"Pinkfong Baby Shark - Kids' Songs & Stories\",\n",
       " '10.23',\n",
       " 'June 17, 2016',\n",
       " '2.',\n",
       " '\"Despacito\"[6]',\n",
       " 'Luis Fonsi',\n",
       " '7.75',\n",
       " 'January 12, 2017',\n",
       " '3.',\n",
       " '\"Johny Johny Yes Papa\"[12]',\n",
       " 'LooLoo Kids',\n",
       " '6.18',\n",
       " 'October 8, 2016',\n",
       " '4.',\n",
       " '\"Shape of You\"[13]',\n",
       " 'Ed Sheeran',\n",
       " '5.62',\n",
       " 'January 30, 2017']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets remove those first 2 empty strings from list \n",
    "\n",
    "l_ele = ['[A]','[B]','[C]','[D]','[E]','[F]','[G]','[H]','[I]','[J]','[K]','[L]']\n",
    "\n",
    "#removing the elements which are present in above list as well\n",
    "a_n = [i  for i in a_new if i not in l_ele and i != '']\n",
    "a_n[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we have all the required details of each youtube video.\n",
    "\n",
    "rank,Name,Artist,Upload_date,Views = [],[],[],[],[]\n",
    "for i in range(0,len(a_n),5):\n",
    "    rank.append(a_n[i])\n",
    "    Name.append((a_n[i+1].split(\"[\"))[0])\n",
    "    Artist.append(a_n[i+2])\n",
    "    Upload_date.append(a_n[i+4])\n",
    "    Views.append(a_n[i+3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## creating the dataframe for Top 30 most-viewed YouTube videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Video name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Upload date</th>\n",
       "      <th>Views(billions)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>\"Baby Shark Dance\"</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>10.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>\"Despacito\"</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>7.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>\"Johny Johny Yes Papa\"</td>\n",
       "      <td>LooLoo Kids</td>\n",
       "      <td>October 8, 2016</td>\n",
       "      <td>6.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>\"Shape of You\"</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>January 30, 2017</td>\n",
       "      <td>5.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>\"See You Again\"</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>April 6, 2015</td>\n",
       "      <td>5.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>\"Bath Song\"</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>May 2, 2018</td>\n",
       "      <td>5.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.</td>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>February 27, 2018</td>\n",
       "      <td>4.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.</td>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>January 31, 2012</td>\n",
       "      <td>4.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>\"Phonics Song with Two Words\"</td>\n",
       "      <td>ChuChu TV</td>\n",
       "      <td>March 6, 2014</td>\n",
       "      <td>4.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>\"Uptown Funk\"</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>November 19, 2014</td>\n",
       "      <td>4.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.</td>\n",
       "      <td>\"Gangnam Style\"</td>\n",
       "      <td>Psy</td>\n",
       "      <td>July 15, 2012</td>\n",
       "      <td>4.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.</td>\n",
       "      <td>\"Dame Tu Cosita\"</td>\n",
       "      <td>El Chombo</td>\n",
       "      <td>April 5, 2018</td>\n",
       "      <td>3.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.</td>\n",
       "      <td>\"Wheels on the Bus\"</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>May 24, 2018</td>\n",
       "      <td>3.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.</td>\n",
       "      <td>\"Sugar\"</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>January 14, 2015</td>\n",
       "      <td>3.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.</td>\n",
       "      <td>\"Roar\"</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>September 5, 2013</td>\n",
       "      <td>3.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.</td>\n",
       "      <td>\"Sorry\"</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td>3.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.</td>\n",
       "      <td>\"Counting Stars\"</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>May 31, 2013</td>\n",
       "      <td>3.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.</td>\n",
       "      <td>\"Thinking Out Loud\"</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>October 7, 2014</td>\n",
       "      <td>3.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.</td>\n",
       "      <td>\"Girls Like You\"</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>May 31, 2018</td>\n",
       "      <td>3.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.</td>\n",
       "      <td>\"Axel F\"</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>June 16, 2009</td>\n",
       "      <td>3.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.</td>\n",
       "      <td>\"Faded\"</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>December 3, 2015</td>\n",
       "      <td>3.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.</td>\n",
       "      <td>\"Dark Horse\"</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>February 20, 2014</td>\n",
       "      <td>3.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.</td>\n",
       "      <td>\"Let Her Go\"</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>July 25, 2012</td>\n",
       "      <td>3.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.</td>\n",
       "      <td>\"Bailando\"</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>April 11, 2014</td>\n",
       "      <td>3.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.</td>\n",
       "      <td>\"Lean On\"</td>\n",
       "      <td>Major Lazer</td>\n",
       "      <td>March 22, 2015</td>\n",
       "      <td>3.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.</td>\n",
       "      <td>\"Shake It Off\"</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>August 18, 2014</td>\n",
       "      <td>3.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.</td>\n",
       "      <td>\"Baa Baa Black Sheep\"</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>June 25, 2018</td>\n",
       "      <td>3.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.</td>\n",
       "      <td>\"Perfect\"</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>November 9, 2017</td>\n",
       "      <td>3.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.</td>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>June 4, 2010</td>\n",
       "      <td>3.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.</td>\n",
       "      <td>\"Mi Gente\"</td>\n",
       "      <td>J Balvin</td>\n",
       "      <td>June 29, 2017</td>\n",
       "      <td>3.04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                   Video name  \\\n",
       "0    1.                           \"Baby Shark Dance\"   \n",
       "1    2.                                  \"Despacito\"   \n",
       "2    3.                       \"Johny Johny Yes Papa\"   \n",
       "3    4.                               \"Shape of You\"   \n",
       "4    5.                              \"See You Again\"   \n",
       "5    6.                                  \"Bath Song\"   \n",
       "6    7.  \"Learning Colors – Colorful Eggs on a Farm\"   \n",
       "7    8.   \"Masha and the Bear – Recipe for Disaster\"   \n",
       "8    9.                \"Phonics Song with Two Words\"   \n",
       "9   10.                                \"Uptown Funk\"   \n",
       "10  11.                              \"Gangnam Style\"   \n",
       "11  12.                             \"Dame Tu Cosita\"   \n",
       "12  13.                          \"Wheels on the Bus\"   \n",
       "13  14.                                      \"Sugar\"   \n",
       "14  15.                                       \"Roar\"   \n",
       "15  16.                                      \"Sorry\"   \n",
       "16  17.                             \"Counting Stars\"   \n",
       "17  18.                          \"Thinking Out Loud\"   \n",
       "18  19.                             \"Girls Like You\"   \n",
       "19  20.                                     \"Axel F\"   \n",
       "20  21.                                      \"Faded\"   \n",
       "21  22.                                 \"Dark Horse\"   \n",
       "22  23.                                 \"Let Her Go\"   \n",
       "23  24.                                   \"Bailando\"   \n",
       "24  25.                                    \"Lean On\"   \n",
       "25  26.                               \"Shake It Off\"   \n",
       "26  27.                        \"Baa Baa Black Sheep\"   \n",
       "27  28.                                    \"Perfect\"   \n",
       "28  29.           \"Waka Waka (This Time for Africa)\"   \n",
       "29  30.                                   \"Mi Gente\"   \n",
       "\n",
       "                                         Artist        Upload date  \\\n",
       "0   Pinkfong Baby Shark - Kids' Songs & Stories      June 17, 2016   \n",
       "1                                    Luis Fonsi   January 12, 2017   \n",
       "2                                   LooLoo Kids    October 8, 2016   \n",
       "3                                    Ed Sheeran   January 30, 2017   \n",
       "4                                   Wiz Khalifa      April 6, 2015   \n",
       "5                    Cocomelon – Nursery Rhymes        May 2, 2018   \n",
       "6                                   Miroshka TV  February 27, 2018   \n",
       "7                                    Get Movies   January 31, 2012   \n",
       "8                                     ChuChu TV      March 6, 2014   \n",
       "9                                   Mark Ronson  November 19, 2014   \n",
       "10                                          Psy      July 15, 2012   \n",
       "11                                    El Chombo      April 5, 2018   \n",
       "12                   Cocomelon – Nursery Rhymes       May 24, 2018   \n",
       "13                                     Maroon 5   January 14, 2015   \n",
       "14                                   Katy Perry  September 5, 2013   \n",
       "15                                Justin Bieber   October 22, 2015   \n",
       "16                                  OneRepublic       May 31, 2013   \n",
       "17                                   Ed Sheeran    October 7, 2014   \n",
       "18                                     Maroon 5       May 31, 2018   \n",
       "19                                   Crazy Frog      June 16, 2009   \n",
       "20                                  Alan Walker   December 3, 2015   \n",
       "21                                   Katy Perry  February 20, 2014   \n",
       "22                                    Passenger      July 25, 2012   \n",
       "23                             Enrique Iglesias     April 11, 2014   \n",
       "24                                  Major Lazer     March 22, 2015   \n",
       "25                                 Taylor Swift    August 18, 2014   \n",
       "26                   Cocomelon – Nursery Rhymes      June 25, 2018   \n",
       "27                                   Ed Sheeran   November 9, 2017   \n",
       "28                                      Shakira       June 4, 2010   \n",
       "29                                     J Balvin      June 29, 2017   \n",
       "\n",
       "   Views(billions)  \n",
       "0            10.23  \n",
       "1             7.75  \n",
       "2             6.18  \n",
       "3             5.62  \n",
       "4             5.42  \n",
       "5             5.01  \n",
       "6             4.56  \n",
       "7             4.48  \n",
       "8             4.48  \n",
       "9             4.47  \n",
       "10            4.35  \n",
       "11            3.86  \n",
       "12            3.70  \n",
       "13            3.65  \n",
       "14            3.53  \n",
       "15            3.51  \n",
       "16            3.51  \n",
       "17            3.41  \n",
       "18            3.24  \n",
       "19            3.24  \n",
       "20            3.23  \n",
       "21            3.23  \n",
       "22            3.18  \n",
       "23            3.17  \n",
       "24            3.17  \n",
       "25            3.15  \n",
       "26            3.14  \n",
       "27            3.10  \n",
       "28            3.06  \n",
       "29            3.04  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\"Rank\":rank,\"Video name\":Name,\"Artist\":Artist,\"Upload date\":Upload_date,\"Views(billions)\":Views})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('top_30_youtube_videos.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2) Scrape the details team India’s international fixtures from bcci.tv.\n",
    "\n",
    "Url = https://www.bcci.tv/.\n",
    "\n",
    "You need to find following details:\n",
    "\n",
    "A) Match title (I.e. 1\n",
    "st ODI)\n",
    "\n",
    "B) Series\n",
    "\n",
    "C) Place\n",
    "\n",
    "D) Date\n",
    "\n",
    "E) Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#site url\n",
    "url = 'https://www.bcci.tv/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#searching an web element for International option using xpath\n",
    "International_fix = driver.find_element_by_xpath('/html/body/div[14]/div/div[1]/div[2]/ul[1]/li[2]/a')\n",
    "\n",
    "International_fix.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#more fixtures option\n",
    "\n",
    "more_fixtures = True\n",
    "while more_fixtures:\n",
    "    try:\n",
    "        more_fix = driver.find_element_by_xpath('/html/body/div[3]/div[2]/div/div/div/div[2]/div[3]/div[2]/div/button')\n",
    "        more_fix.click()\n",
    "    except:\n",
    "        more_fixtures = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to get date\n",
    "date_d = driver.find_elements_by_xpath('//h5[@class=\"ng-binding\"]')\n",
    "date_d = [i.text for i in date_d]\n",
    "\n",
    "#to get time info\n",
    "time_d = driver.find_elements_by_xpath('//h5[@class=\"text-right ng-binding\"]')\n",
    "time_d = [i.text for i in time_d]\n",
    "\n",
    "#to get series info\n",
    "series_d = driver.find_elements_by_xpath('//span[@class=\"ng-binding\"]')\n",
    "series_d = [i.text for i in series_d]\n",
    "\n",
    "#to get match title\n",
    "title_place_ = driver.find_elements_by_xpath('//div[@class=\"fix-place ng-binding ng-scope\"]')\n",
    "#filling out missing values with '-'\n",
    "Match_title = [(i.text.split(\"-\"))[0] if '-' in i.text else '-' for i in title_place_ ]\n",
    "\n",
    "#to get place info\n",
    "place_d = driver.find_elements_by_xpath('//span[@class=\"ng-binding ng-scope\"]')\n",
    "place_d = [i.text for i in place_d]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## creating the Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match title</th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2nd T20I</td>\n",
       "      <td>SRI LANKA TOUR OF INDIA T20 SERIES 2022</td>\n",
       "      <td>Himachal Pradesh Cricket Association Stadium,</td>\n",
       "      <td>26 FEB 2022</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3rd T20I</td>\n",
       "      <td>SRI LANKA TOUR OF INDIA T20 SERIES 2022</td>\n",
       "      <td>Himachal Pradesh Cricket Association Stadium,</td>\n",
       "      <td>27 FEB 2022</td>\n",
       "      <td>7:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1st Test</td>\n",
       "      <td>SRI LANKA TOUR OF INDIA TEST SERIES 2022</td>\n",
       "      <td>Punjab Cricket Association IS Bindra Stadium,</td>\n",
       "      <td>4 MAR 2022</td>\n",
       "      <td>9:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-</td>\n",
       "      <td>ICC WOMENS WORLD CUP 2022</td>\n",
       "      <td>Bay Oval,</td>\n",
       "      <td>6 MAR 2022</td>\n",
       "      <td>6:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-</td>\n",
       "      <td>ICC WOMENS WORLD CUP 2022</td>\n",
       "      <td>Seddon Park,</td>\n",
       "      <td>10 MAR 2022</td>\n",
       "      <td>6:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2nd Test</td>\n",
       "      <td>SRI LANKA TOUR OF INDIA TEST SERIES 2022</td>\n",
       "      <td>M Chinnaswamy Stadium,</td>\n",
       "      <td>12 MAR 2022</td>\n",
       "      <td>12:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-</td>\n",
       "      <td>ICC WOMENS WORLD CUP 2022</td>\n",
       "      <td>Seddon Park,</td>\n",
       "      <td>12 MAR 2022</td>\n",
       "      <td>6:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-</td>\n",
       "      <td>ICC WOMENS WORLD CUP 2022</td>\n",
       "      <td>Bay Oval,</td>\n",
       "      <td>16 MAR 2022</td>\n",
       "      <td>6:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-</td>\n",
       "      <td>ICC WOMENS WORLD CUP 2022</td>\n",
       "      <td>Eden Park,</td>\n",
       "      <td>19 MAR 2022</td>\n",
       "      <td>6:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-</td>\n",
       "      <td>ICC WOMENS WORLD CUP 2022</td>\n",
       "      <td>Seddon Park,</td>\n",
       "      <td>22 MAR 2022</td>\n",
       "      <td>6:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-</td>\n",
       "      <td>ICC WOMENS WORLD CUP 2022</td>\n",
       "      <td>Hagley Oval,</td>\n",
       "      <td>28 MAR 2022</td>\n",
       "      <td>6:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1st T20I</td>\n",
       "      <td>SOUTH AFRICA TOUR OF INDIA T20 SERIES 2022</td>\n",
       "      <td>MA Chidambaram Stadium,</td>\n",
       "      <td>9 JUN 2022</td>\n",
       "      <td>7:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2nd T20I</td>\n",
       "      <td>SOUTH AFRICA TOUR OF INDIA T20 SERIES 2022</td>\n",
       "      <td>M Chinnaswamy Stadium,</td>\n",
       "      <td>12 JUN 2022</td>\n",
       "      <td>7:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3rd T20I</td>\n",
       "      <td>SOUTH AFRICA TOUR OF INDIA T20 SERIES 2022</td>\n",
       "      <td>Vidarbha Cricket Association Stadium,</td>\n",
       "      <td>14 JUN 2022</td>\n",
       "      <td>7:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>4th T20I</td>\n",
       "      <td>SOUTH AFRICA TOUR OF INDIA T20 SERIES 2022</td>\n",
       "      <td>Saurashtra Cricket Association Stadium,</td>\n",
       "      <td>17 JUN 2022</td>\n",
       "      <td>7:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5th T20I</td>\n",
       "      <td>SOUTH AFRICA TOUR OF INDIA T20 SERIES 2022</td>\n",
       "      <td>Arun Jaitley Stadium,</td>\n",
       "      <td>19 JUN 2022</td>\n",
       "      <td>7:30 PM IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Match title                                      Series  \\\n",
       "0    2nd T20I      SRI LANKA TOUR OF INDIA T20 SERIES 2022   \n",
       "1    3rd T20I      SRI LANKA TOUR OF INDIA T20 SERIES 2022   \n",
       "2    1st Test     SRI LANKA TOUR OF INDIA TEST SERIES 2022   \n",
       "3            -                   ICC WOMENS WORLD CUP 2022   \n",
       "4            -                   ICC WOMENS WORLD CUP 2022   \n",
       "5    2nd Test     SRI LANKA TOUR OF INDIA TEST SERIES 2022   \n",
       "6            -                   ICC WOMENS WORLD CUP 2022   \n",
       "7            -                   ICC WOMENS WORLD CUP 2022   \n",
       "8            -                   ICC WOMENS WORLD CUP 2022   \n",
       "9            -                   ICC WOMENS WORLD CUP 2022   \n",
       "10           -                   ICC WOMENS WORLD CUP 2022   \n",
       "11   1st T20I   SOUTH AFRICA TOUR OF INDIA T20 SERIES 2022   \n",
       "12   2nd T20I   SOUTH AFRICA TOUR OF INDIA T20 SERIES 2022   \n",
       "13   3rd T20I   SOUTH AFRICA TOUR OF INDIA T20 SERIES 2022   \n",
       "14   4th T20I   SOUTH AFRICA TOUR OF INDIA T20 SERIES 2022   \n",
       "15   5th T20I   SOUTH AFRICA TOUR OF INDIA T20 SERIES 2022   \n",
       "\n",
       "                                            Place         Date          Time  \n",
       "0   Himachal Pradesh Cricket Association Stadium,  26 FEB 2022   7:00 PM IST  \n",
       "1   Himachal Pradesh Cricket Association Stadium,  27 FEB 2022   7:00 PM IST  \n",
       "2   Punjab Cricket Association IS Bindra Stadium,   4 MAR 2022   9:30 AM IST  \n",
       "3                                       Bay Oval,   6 MAR 2022   6:30 AM IST  \n",
       "4                                    Seddon Park,  10 MAR 2022   6:30 AM IST  \n",
       "5                          M Chinnaswamy Stadium,  12 MAR 2022  12:30 PM IST  \n",
       "6                                    Seddon Park,  12 MAR 2022   6:30 AM IST  \n",
       "7                                       Bay Oval,  16 MAR 2022   6:30 AM IST  \n",
       "8                                      Eden Park,  19 MAR 2022   6:30 AM IST  \n",
       "9                                    Seddon Park,  22 MAR 2022   6:30 AM IST  \n",
       "10                                   Hagley Oval,  28 MAR 2022   6:30 AM IST  \n",
       "11                        MA Chidambaram Stadium,   9 JUN 2022   7:30 PM IST  \n",
       "12                         M Chinnaswamy Stadium,  12 JUN 2022   7:30 PM IST  \n",
       "13          Vidarbha Cricket Association Stadium,  14 JUN 2022   7:30 PM IST  \n",
       "14        Saurashtra Cricket Association Stadium,  17 JUN 2022   7:30 PM IST  \n",
       "15                          Arun Jaitley Stadium,  19 JUN 2022   7:30 PM IST  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\"Match title\":Match_title,\"Series\":series_d,\"Place\":place_d,\"Date\":date_d,\"Time\":time_d})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## creating the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"BCCI_International_Fixtures\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3) Scrape the details of selenium exception from guru99.com.\n",
    "\n",
    "Url = https://www.guru99.com/\n",
    "\n",
    "You need to find following details:\n",
    "\n",
    "A) Name\n",
    "\n",
    "B) Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#site url\n",
    "url = 'https://www.guru99.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting selenium option under testing section\n",
    "\n",
    "selenium_op = driver.find_element_by_xpath('/html/body/div[1]/div/div/div/main/div/article/div/div[1]/div[2]/div[1]/div/ul[1]/li[3]/a')\n",
    "\n",
    "selenium_op.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting tutorial of Selenium Exception Handling (Common Exceptions List)\n",
    "\n",
    "exception_handling = driver.find_element_by_xpath('/html/body/div[1]/div/div/div/main/div/article/div/div/table[5]/tbody/tr[34]/td[1]/a/strong')\n",
    "\n",
    "exception_handling.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(driver.page_source,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gettng the source data of table\n",
    "result = soup.find('table',{'class':'table table-striped'})\n",
    "\n",
    "new_res = result.find_all('td')\n",
    "new_res = [i.text for i in new_res]\n",
    "\n",
    "#for getting an exception name\n",
    "exc_name = [new_res[i]  for i in range(len(new_res)) if i % 2 == 0]\n",
    "\n",
    "#for getting a description \n",
    "desc = [new_res[i] for i in range(len(new_res)) if i % 2 != 0  ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## creating the Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Exception name</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ElementNotVisibleException</td>\n",
       "      <td>This type of Selenium exception occurs when an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ElementNotSelectableException</td>\n",
       "      <td>This Selenium exception occurs when an element...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NoSuchElementException</td>\n",
       "      <td>This Exception occurs if an element could not ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NoSuchFrameException</td>\n",
       "      <td>This Exception occurs if the frame target to b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NoAlertPresentException</td>\n",
       "      <td>This Exception occurs when you switch to no pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NoSuchWindowException</td>\n",
       "      <td>This Exception occurs if the window target to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>StaleElementReferenceException</td>\n",
       "      <td>This Selenium exception occurs happens when th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SessionNotFoundException</td>\n",
       "      <td>The WebDriver is acting after you quit the bro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>TimeoutException</td>\n",
       "      <td>Thrown when there is not enough time for a com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>WebDriverException</td>\n",
       "      <td>This Exception takes place when the WebDriver ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ConnectionClosedException</td>\n",
       "      <td>This type of Exception takes place when there ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ElementClickInterceptedException</td>\n",
       "      <td>The command may not be completed as the elemen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ElementNotInteractableException</td>\n",
       "      <td>This Selenium exception is thrown when any ele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ErrorInResponseException</td>\n",
       "      <td>This happens while interacting with the Firefo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ErrorHandler.UnknownServerException</td>\n",
       "      <td>Exception is used as a placeholder in case if ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ImeActivationFailedException</td>\n",
       "      <td>This expectation will occur when IME engine ac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ImeNotAvailableException</td>\n",
       "      <td>It takes place when IME support is unavailable.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>InsecureCertificateException</td>\n",
       "      <td>Navigation made the user agent to hit a certif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>InvalidArgumentException</td>\n",
       "      <td>It occurs when an argument does not belong to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>InvalidCookieDomainException</td>\n",
       "      <td>This happens when you try to add a cookie unde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>InvalidCoordinatesException</td>\n",
       "      <td>This type of Exception matches an interacting ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>InvalidElementStateExceptio</td>\n",
       "      <td>It occurs when command can’t be finished when ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>InvalidSessionIdException</td>\n",
       "      <td>This Exception took place when the given sessi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>InvalidSwitchToTargetException</td>\n",
       "      <td>This occurs when the frame or window target to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>JavascriptException</td>\n",
       "      <td>This issue occurs while executing JavaScript g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>JsonException</td>\n",
       "      <td>It occurs when you afford to get the session w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NoSuchAttributeException</td>\n",
       "      <td>This kind of Exception occurs when the attribu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>MoveTargetOutOfBoundsException</td>\n",
       "      <td>It takes place if the target provided to the A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NoSuchContextException</td>\n",
       "      <td>ContextAware does mobile device testing.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NoSuchCookieException</td>\n",
       "      <td>This Exception occurs when no cookie matching ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>NotFoundException</td>\n",
       "      <td>This Exception is a subclass of WebDriverExcep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>RemoteDriverServerException</td>\n",
       "      <td>This Selenium exception is thrown when the ser...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>ScreenshotException</td>\n",
       "      <td>It is not possible to capture a screen.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>SessionNotCreatedException</td>\n",
       "      <td>It happens when a new session could not be suc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>UnableToSetCookieException</td>\n",
       "      <td>This occurs if a driver is unable to set a coo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>UnexpectedTagNameException</td>\n",
       "      <td>Happens if a support class did not get a web e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>UnhandledAlertException</td>\n",
       "      <td>This expectation occurs when there is an alert...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>UnexpectedAlertPresentException</td>\n",
       "      <td>It occurs when there is the appearance of an u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>UnknownMethodException</td>\n",
       "      <td>This Exception happens when the requested comm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>UnreachableBrowserException</td>\n",
       "      <td>This Exception occurs only when the browser is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>UnsupportedCommandException</td>\n",
       "      <td>This occurs when remote WebDriver does n’t sen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Exception name  \\\n",
       "0            ElementNotVisibleException   \n",
       "1         ElementNotSelectableException   \n",
       "2                NoSuchElementException   \n",
       "3                  NoSuchFrameException   \n",
       "4               NoAlertPresentException   \n",
       "5                 NoSuchWindowException   \n",
       "6        StaleElementReferenceException   \n",
       "7              SessionNotFoundException   \n",
       "8                      TimeoutException   \n",
       "9                    WebDriverException   \n",
       "10            ConnectionClosedException   \n",
       "11     ElementClickInterceptedException   \n",
       "12      ElementNotInteractableException   \n",
       "13             ErrorInResponseException   \n",
       "14  ErrorHandler.UnknownServerException   \n",
       "15         ImeActivationFailedException   \n",
       "16             ImeNotAvailableException   \n",
       "17         InsecureCertificateException   \n",
       "18             InvalidArgumentException   \n",
       "19         InvalidCookieDomainException   \n",
       "20          InvalidCoordinatesException   \n",
       "21          InvalidElementStateExceptio   \n",
       "22            InvalidSessionIdException   \n",
       "23       InvalidSwitchToTargetException   \n",
       "24                  JavascriptException   \n",
       "25                        JsonException   \n",
       "26             NoSuchAttributeException   \n",
       "27       MoveTargetOutOfBoundsException   \n",
       "28               NoSuchContextException   \n",
       "29                NoSuchCookieException   \n",
       "30                    NotFoundException   \n",
       "31          RemoteDriverServerException   \n",
       "32                  ScreenshotException   \n",
       "33           SessionNotCreatedException   \n",
       "34           UnableToSetCookieException   \n",
       "35           UnexpectedTagNameException   \n",
       "36              UnhandledAlertException   \n",
       "37      UnexpectedAlertPresentException   \n",
       "38               UnknownMethodException   \n",
       "39          UnreachableBrowserException   \n",
       "40          UnsupportedCommandException   \n",
       "\n",
       "                                          Description  \n",
       "0   This type of Selenium exception occurs when an...  \n",
       "1   This Selenium exception occurs when an element...  \n",
       "2   This Exception occurs if an element could not ...  \n",
       "3   This Exception occurs if the frame target to b...  \n",
       "4   This Exception occurs when you switch to no pr...  \n",
       "5   This Exception occurs if the window target to ...  \n",
       "6   This Selenium exception occurs happens when th...  \n",
       "7   The WebDriver is acting after you quit the bro...  \n",
       "8   Thrown when there is not enough time for a com...  \n",
       "9   This Exception takes place when the WebDriver ...  \n",
       "10  This type of Exception takes place when there ...  \n",
       "11  The command may not be completed as the elemen...  \n",
       "12  This Selenium exception is thrown when any ele...  \n",
       "13  This happens while interacting with the Firefo...  \n",
       "14  Exception is used as a placeholder in case if ...  \n",
       "15  This expectation will occur when IME engine ac...  \n",
       "16    It takes place when IME support is unavailable.  \n",
       "17  Navigation made the user agent to hit a certif...  \n",
       "18  It occurs when an argument does not belong to ...  \n",
       "19  This happens when you try to add a cookie unde...  \n",
       "20  This type of Exception matches an interacting ...  \n",
       "21  It occurs when command can’t be finished when ...  \n",
       "22  This Exception took place when the given sessi...  \n",
       "23  This occurs when the frame or window target to...  \n",
       "24  This issue occurs while executing JavaScript g...  \n",
       "25  It occurs when you afford to get the session w...  \n",
       "26  This kind of Exception occurs when the attribu...  \n",
       "27  It takes place if the target provided to the A...  \n",
       "28           ContextAware does mobile device testing.  \n",
       "29  This Exception occurs when no cookie matching ...  \n",
       "30  This Exception is a subclass of WebDriverExcep...  \n",
       "31  This Selenium exception is thrown when the ser...  \n",
       "32            It is not possible to capture a screen.  \n",
       "33  It happens when a new session could not be suc...  \n",
       "34  This occurs if a driver is unable to set a coo...  \n",
       "35  Happens if a support class did not get a web e...  \n",
       "36  This expectation occurs when there is an alert...  \n",
       "37  It occurs when there is the appearance of an u...  \n",
       "38  This Exception happens when the requested comm...  \n",
       "39  This Exception occurs only when the browser is...  \n",
       "40  This occurs when remote WebDriver does n’t sen...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\"Exception name\":exc_name,\"Description\":desc})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## creating the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Common Exceptions in Selenium Web driver\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4)Scrape the details of State-wise GDP of India from statisticstime.com.\n",
    "\n",
    "Url = http://statisticstimes.com/\n",
    "\n",
    "You have to find following details:\n",
    "\n",
    "A) Rank\n",
    "\n",
    "B) State\n",
    "\n",
    "C) GSDP\n",
    "\n",
    "D) GSDP\n",
    "\n",
    "E) Share\n",
    "\n",
    "F) GDP($ billion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#site url\n",
    "url = 'http://statisticstimes.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the web element for economy drop down option\n",
    "\n",
    "economy_op = driver.find_element_by_xpath('/html/body/div[2]/div[1]/div[2]/div[2]/button')\n",
    "\n",
    "economy_op.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now choosing the India as option\n",
    "\n",
    "India_op = driver.find_element_by_xpath('/html/body/div[2]/div[1]/div[2]/div[2]/div/a[3]')\n",
    "\n",
    "India_op.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting the option of GDP of Indian states option\n",
    "\n",
    "GDP_states = driver.find_element_by_xpath('/html/body/div[2]/div[2]/div[2]/ul/li[1]/a')\n",
    "\n",
    "GDP_states.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(driver.page_source,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the source data of table\n",
    "\n",
    "result = soup.find('table',{'id':'table_id'})\n",
    "\n",
    "#getting the all the information of GDP for each states\n",
    "result_n = result.find_all('tr',{'role':'row'})\n",
    "result_n = [(i.text.split(\"\\n\"))[1:] for i in result_n][2:]\n",
    "\n",
    "#for State name\n",
    "result_name = result.find_all('td',{'class':'name'})\n",
    "state_name = [i.text for i in result_name][:-1]\n",
    "\n",
    "#for rank info\n",
    "result_rank = result.find_all('td',{'class':'data1'})\n",
    "rank = [i.text for i in result_rank][:-1]\n",
    "\n",
    "#for Share info\n",
    "share = []\n",
    "try:\n",
    "    for i in result_n:\n",
    "        share.append(i[2])\n",
    "except:\n",
    "    share.append('-')\n",
    "\n",
    "#for GDP($ billion)\n",
    "GDP = []\n",
    "try:\n",
    "    for i in result_n:\n",
    "        GDP.append(i[3])\n",
    "except:\n",
    "    GDP.append('-')\n",
    "\n",
    "#for GSDP (Cr INR at Current prices)\n",
    "GSDP_19_20,GSDP_18_19 = [],[]\n",
    "\n",
    "try:\n",
    "    for i in result_n:\n",
    "        GSDP_19_20.append(i[0])\n",
    "except:\n",
    "    GSDP_19_20.append('-')\n",
    "try:\n",
    "    for i in result_n:\n",
    "        GSDP_18_19.append(i[1])\n",
    "except:\n",
    "    GSDP_18_19.append('-')\n",
    "\n",
    "#for GSDP (Cr INR at 2011-12 prices)\n",
    "GSDP1_19_20,GSDP1_18_19 = [],[]\n",
    "\n",
    "try:\n",
    "    for i in result_n:\n",
    "        GSDP1_19_20.append(i[4])\n",
    "except:\n",
    "    GSDP1_19_20.append('-')\n",
    "try:\n",
    "    for i in result_n:\n",
    "        GSDP1_18_19.append(i[5])\n",
    "except:\n",
    "    GSDP1_18_19.append('-')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## creating the Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP_current_18_19</th>\n",
       "      <th>GSDP_current_19_20</th>\n",
       "      <th>GSDP(at_2011)_19_20</th>\n",
       "      <th>GSDP(at_2011)_18_19</th>\n",
       "      <th>Share</th>\n",
       "      <th>GDP($ billion)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>2,039,074</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>399.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>1,845,853</td>\n",
       "      <td>1,312,929</td>\n",
       "      <td>1,215,307</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>247.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>1,687,818</td>\n",
       "      <td>1,166,817</td>\n",
       "      <td>1,123,982</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>240.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>1,186,379</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>228.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>1,631,977</td>\n",
       "      <td>1,156,039</td>\n",
       "      <td>1,091,077</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>226.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,089,898</td>\n",
       "      <td>1,253,832</td>\n",
       "      <td>793,223</td>\n",
       "      <td>739,525</td>\n",
       "      <td>5.77%</td>\n",
       "      <td>165.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>942,586</td>\n",
       "      <td>1,020,989</td>\n",
       "      <td>711,627</td>\n",
       "      <td>677,428</td>\n",
       "      <td>4.99%</td>\n",
       "      <td>143.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>862,957</td>\n",
       "      <td>972,782</td>\n",
       "      <td>672,018</td>\n",
       "      <td>621,301</td>\n",
       "      <td>4.57%</td>\n",
       "      <td>131.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>861,031</td>\n",
       "      <td>969,604</td>\n",
       "      <td>663,258</td>\n",
       "      <td>612,828</td>\n",
       "      <td>4.56%</td>\n",
       "      <td>130.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>809,592</td>\n",
       "      <td>906,672</td>\n",
       "      <td>561,801</td>\n",
       "      <td>522,009</td>\n",
       "      <td>4.29%</td>\n",
       "      <td>122.977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>781,653</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>559,412</td>\n",
       "      <td>4.14%</td>\n",
       "      <td>118.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>774,870</td>\n",
       "      <td>856,112</td>\n",
       "      <td>634,408</td>\n",
       "      <td>590,569</td>\n",
       "      <td>4.10%</td>\n",
       "      <td>117.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>734,163</td>\n",
       "      <td>831,610</td>\n",
       "      <td>572,240</td>\n",
       "      <td>531,085</td>\n",
       "      <td>3.89%</td>\n",
       "      <td>111.519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>530,363</td>\n",
       "      <td>611,804</td>\n",
       "      <td>414,977</td>\n",
       "      <td>375,651</td>\n",
       "      <td>2.81%</td>\n",
       "      <td>80.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>526,376</td>\n",
       "      <td>574,760</td>\n",
       "      <td>418,868</td>\n",
       "      <td>397,669</td>\n",
       "      <td>2.79%</td>\n",
       "      <td>79.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>487,805</td>\n",
       "      <td>521,275</td>\n",
       "      <td>396,499</td>\n",
       "      <td>376,877</td>\n",
       "      <td>2.58%</td>\n",
       "      <td>74.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>315,881</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>234,048</td>\n",
       "      <td>1.67%</td>\n",
       "      <td>47.982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>304,063</td>\n",
       "      <td>329,180</td>\n",
       "      <td>243,477</td>\n",
       "      <td>231,182</td>\n",
       "      <td>1.61%</td>\n",
       "      <td>46.187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>297,204</td>\n",
       "      <td>328,598</td>\n",
       "      <td>240,036</td>\n",
       "      <td>224,986</td>\n",
       "      <td>1.57%</td>\n",
       "      <td>45.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>245,895</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>193,273</td>\n",
       "      <td>1.30%</td>\n",
       "      <td>37.351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>155,956</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>112,755</td>\n",
       "      <td>0.83%</td>\n",
       "      <td>23.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>153,845</td>\n",
       "      <td>165,472</td>\n",
       "      <td>124,403</td>\n",
       "      <td>117,851</td>\n",
       "      <td>0.81%</td>\n",
       "      <td>23.369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>73,170</td>\n",
       "      <td>80,449</td>\n",
       "      <td>63,408</td>\n",
       "      <td>57,787</td>\n",
       "      <td>0.39%</td>\n",
       "      <td>11.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>49,845</td>\n",
       "      <td>55,984</td>\n",
       "      <td>40,583</td>\n",
       "      <td>36,963</td>\n",
       "      <td>0.26%</td>\n",
       "      <td>7.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>42,114</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>31,192</td>\n",
       "      <td>0.22%</td>\n",
       "      <td>6.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>34,433</td>\n",
       "      <td>38,253</td>\n",
       "      <td>25,093</td>\n",
       "      <td>23,013</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>33,481</td>\n",
       "      <td>36,572</td>\n",
       "      <td>26,695</td>\n",
       "      <td>24,682</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>28,723</td>\n",
       "      <td>32,496</td>\n",
       "      <td>20,017</td>\n",
       "      <td>18,722</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>27,870</td>\n",
       "      <td>31,790</td>\n",
       "      <td>20,673</td>\n",
       "      <td>19,300</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>27,283</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>17,647</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>4.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>24,603</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>16,676</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>3.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>22,287</td>\n",
       "      <td>26,503</td>\n",
       "      <td>18,797</td>\n",
       "      <td>16,478</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>3.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>---</td>\n",
       "      <td>---</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                      State GSDP_current_18_19 GSDP_current_19_20  \\\n",
       "0     1                Maharashtra          2,632,792                  -   \n",
       "1     2                 Tamil Nadu          1,630,208          1,845,853   \n",
       "2     3              Uttar Pradesh          1,584,764          1,687,818   \n",
       "3     4                    Gujarat          1,502,899                  -   \n",
       "4     5                  Karnataka          1,493,127          1,631,977   \n",
       "5     6                West Bengal          1,089,898          1,253,832   \n",
       "6     7                  Rajasthan            942,586          1,020,989   \n",
       "7     8             Andhra Pradesh            862,957            972,782   \n",
       "8     9                  Telangana            861,031            969,604   \n",
       "9    10             Madhya Pradesh            809,592            906,672   \n",
       "10   11                     Kerala            781,653                  -   \n",
       "11   12                      Delhi            774,870            856,112   \n",
       "12   13                    Haryana            734,163            831,610   \n",
       "13   14                      Bihar            530,363            611,804   \n",
       "14   15                     Punjab            526,376            574,760   \n",
       "15   16                     Odisha            487,805            521,275   \n",
       "16   17                      Assam            315,881                  -   \n",
       "17   18               Chhattisgarh            304,063            329,180   \n",
       "18   19                  Jharkhand            297,204            328,598   \n",
       "19   20                Uttarakhand            245,895                  -   \n",
       "20   21            Jammu & Kashmir            155,956                  -   \n",
       "21   22           Himachal Pradesh            153,845            165,472   \n",
       "22   23                        Goa             73,170             80,449   \n",
       "23   24                    Tripura             49,845             55,984   \n",
       "24   25                 Chandigarh             42,114                  -   \n",
       "25   26                 Puducherry             34,433             38,253   \n",
       "26   27                  Meghalaya             33,481             36,572   \n",
       "27   28                     Sikkim             28,723             32,496   \n",
       "28   29                    Manipur             27,870             31,790   \n",
       "29   30                   Nagaland             27,283                  -   \n",
       "30   31          Arunachal Pradesh             24,603                  -   \n",
       "31   32                    Mizoram             22,287             26,503   \n",
       "32   33  Andaman & Nicobar Islands                ---                ---   \n",
       "\n",
       "   GSDP(at_2011)_19_20 GSDP(at_2011)_18_19   Share GDP($ billion)  \n",
       "0                    -           2,039,074  13.94%        399.921  \n",
       "1            1,312,929           1,215,307   8.63%        247.629  \n",
       "2            1,166,817           1,123,982   8.39%        240.726  \n",
       "3                    -           1,186,379   7.96%        228.290  \n",
       "4            1,156,039           1,091,077   7.91%        226.806  \n",
       "5              793,223             739,525   5.77%        165.556  \n",
       "6              711,627             677,428   4.99%        143.179  \n",
       "7              672,018             621,301   4.57%        131.083  \n",
       "8              663,258             612,828   4.56%        130.791  \n",
       "9              561,801             522,009   4.29%        122.977  \n",
       "10                   -             559,412   4.14%        118.733  \n",
       "11             634,408             590,569   4.10%        117.703  \n",
       "12             572,240             531,085   3.89%        111.519  \n",
       "13             414,977             375,651   2.81%         80.562  \n",
       "14             418,868             397,669   2.79%         79.957  \n",
       "15             396,499             376,877   2.58%         74.098  \n",
       "16                   -             234,048   1.67%         47.982  \n",
       "17             243,477             231,182   1.61%         46.187  \n",
       "18             240,036             224,986   1.57%         45.145  \n",
       "19                   -             193,273   1.30%         37.351  \n",
       "20                   -             112,755   0.83%         23.690  \n",
       "21             124,403             117,851   0.81%         23.369  \n",
       "22              63,408              57,787   0.39%         11.115  \n",
       "23              40,583              36,963   0.26%          7.571  \n",
       "24                   -              31,192   0.22%          6.397  \n",
       "25              25,093              23,013   0.18%          5.230  \n",
       "26              26,695              24,682   0.18%          5.086  \n",
       "27              20,017              18,722   0.15%          4.363  \n",
       "28              20,673              19,300   0.15%          4.233  \n",
       "29                   -              17,647   0.14%          4.144  \n",
       "30                   -              16,676   0.13%          3.737  \n",
       "31              18,797              16,478   0.12%          3.385  \n",
       "32                   -                   -       -              -  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\"Rank\":rank,\"State\":state_name,\"GSDP_current_18_19\":GSDP_18_19,\"GSDP_current_19_20\":GSDP_19_20,\n",
    "                   \"GSDP(at_2011)_19_20\":GSDP1_19_20,\"GSDP(at_2011)_18_19\":GSDP1_18_19,\"Share\":share,\n",
    "                   \"GDP($ billion)\":GDP})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## creating the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"GDP_of_Indian_states\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5)Scrape the details of trending repositories on Github.com.\n",
    "\n",
    "Url = https://github.com/\n",
    "\n",
    "You have to find the following details:\n",
    "\n",
    "A) Repository title\n",
    "\n",
    "B) Repository description\n",
    "\n",
    "C) Contributors count\n",
    "\n",
    "D) Language used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#site url\n",
    "url = 'https://github.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the web element for explore option drop down\n",
    "\n",
    "exp_drop_down = driver.find_element_by_xpath('/html/body/div[1]/header/div/div[2]/nav/ul/li[4]/details/summary')\n",
    "\n",
    "exp_drop_down.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the web element for explore github option\n",
    "\n",
    "explore_github = driver.find_element_by_xpath('/html/body/div[1]/header/div/div[2]/nav/ul/li[4]/details/div/ul/li[1]/a')\n",
    "\n",
    "explore_github.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#searching with trending option\n",
    "trending = driver.find_element_by_xpath('/html/body/div[4]/main/div[1]/nav/div/a[3]')\n",
    "\n",
    "trending.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(driver.page_source,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = soup.find_all('article',{'class':'Box-row'})\n",
    "\n",
    "#for repository title\n",
    "rep_title = []\n",
    "for i in range(len(result)):\n",
    "    a_new = result[i].find('h1',{'class':'h3 lh-condensed'})\n",
    "    rep_title.append((a_new.text.strip().split(\"/\"))[1].strip(\" \\n\"))\n",
    "\n",
    "#for repository description\n",
    "rep_desc = []\n",
    "for i in range(len(result)):\n",
    "    try:\n",
    "        a_new = result[i].find('p',{'class':'col-9 color-fg-muted my-1 pr-4'})\n",
    "        rep_desc.append(a_new.text.strip())\n",
    "    except:\n",
    "        rep_desc.append('-')\n",
    "        \n",
    "#for languages used\n",
    "langs_used = []\n",
    "for i in range(len(result)):\n",
    "    try:\n",
    "        a_new = result[i].find('span',{'itemprop':'programmingLanguage'})\n",
    "        langs_used.append(a_new.text.strip())\n",
    "    except:\n",
    "        langs_used.append(\"-\")\n",
    "\n",
    "#for contributors count\n",
    "contri_counts = []\n",
    "for i in range(len(result)):\n",
    "    a_new = result[i].find('span',{'class':'d-inline-block mr-3'})\n",
    "    a_n = a_new.find_all('a',{'class':'d-inline-block'})\n",
    "    contri_counts.append(len(a_n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## creating the Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repository title</th>\n",
       "      <th>Repository description</th>\n",
       "      <th>Contributors count</th>\n",
       "      <th>Language used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JD-SHOPPER</td>\n",
       "      <td>京东自动下单 (自动登录,指定时间预约商品,商品补货监控,自动加购物车,自动下单)</td>\n",
       "      <td>2</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>advisory-database</td>\n",
       "      <td>Security vulnerability database inclusive of C...</td>\n",
       "      <td>3</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>netdata</td>\n",
       "      <td>Real-time performance monitoring, done right! ...</td>\n",
       "      <td>5</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JoltPhysics</td>\n",
       "      <td>A multi core friendly rigid body physics and c...</td>\n",
       "      <td>3</td>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kr_autonomous_flight</td>\n",
       "      <td>Autonomous flight system for aerial robots</td>\n",
       "      <td>5</td>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>hacker-laws-zh</td>\n",
       "      <td>💻📖对开发人员有用的定律、理论、原则和模式。(Laws, Theories, Princip...</td>\n",
       "      <td>5</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>awesome-tunneling</td>\n",
       "      <td>List of ngrok alternatives and other ngrok-lik...</td>\n",
       "      <td>5</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fucking-algorithm</td>\n",
       "      <td>刷算法全靠套路，认准 labuladong 就够了！English version supp...</td>\n",
       "      <td>5</td>\n",
       "      <td>Markdown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>autocomplete</td>\n",
       "      <td>Fig adds autocomplete to your terminal.</td>\n",
       "      <td>5</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>openpilot</td>\n",
       "      <td>openpilot is an open source driver assistance ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>beam</td>\n",
       "      <td>A simple message board for your organization o...</td>\n",
       "      <td>5</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Hitomi-Downloader</td>\n",
       "      <td>🍰 Desktop utility to download images/videos/mu...</td>\n",
       "      <td>5</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Voron-2</td>\n",
       "      <td>Voron 2 CoreXY 3D Printer design</td>\n",
       "      <td>5</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ant-design-vue</td>\n",
       "      <td>🌈 An enterprise-class UI components based on A...</td>\n",
       "      <td>5</td>\n",
       "      <td>Vue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Geographical-Adventures</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>C#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>fastapi</td>\n",
       "      <td>FastAPI framework, high performance, easy to l...</td>\n",
       "      <td>5</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>dooringx</td>\n",
       "      <td>快速高效搭建可视化拖拽平台</td>\n",
       "      <td>5</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>folly</td>\n",
       "      <td>An open-source C++ library developed and used ...</td>\n",
       "      <td>5</td>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>yao</td>\n",
       "      <td>Yao A low code engine to create web services a...</td>\n",
       "      <td>2</td>\n",
       "      <td>Go</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>graphql-engine</td>\n",
       "      <td>Blazing fast, instant realtime GraphQL APIs on...</td>\n",
       "      <td>5</td>\n",
       "      <td>Haskell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>preserve-cd</td>\n",
       "      <td>Game Preservation Project</td>\n",
       "      <td>2</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>plasticity</td>\n",
       "      <td>-</td>\n",
       "      <td>3</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>advanced-java</td>\n",
       "      <td>😮 Core Interview Questions &amp; Answers For Exper...</td>\n",
       "      <td>5</td>\n",
       "      <td>Java</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Anime-Girls-Holding-Programming-Books</td>\n",
       "      <td>Anime Girls Holding Programming Books</td>\n",
       "      <td>5</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>leetcode-master</td>\n",
       "      <td>《代码随想录》LeetCode 刷题攻略：200道经典题目刷题顺序，共60w字的详细图解，视...</td>\n",
       "      <td>5</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Repository title  \\\n",
       "0                              JD-SHOPPER   \n",
       "1                       advisory-database   \n",
       "2                                 netdata   \n",
       "3                             JoltPhysics   \n",
       "4                    kr_autonomous_flight   \n",
       "5                          hacker-laws-zh   \n",
       "6                       awesome-tunneling   \n",
       "7                       fucking-algorithm   \n",
       "8                            autocomplete   \n",
       "9                               openpilot   \n",
       "10                                   beam   \n",
       "11                      Hitomi-Downloader   \n",
       "12                                Voron-2   \n",
       "13                         ant-design-vue   \n",
       "14                Geographical-Adventures   \n",
       "15                                fastapi   \n",
       "16                               dooringx   \n",
       "17                                  folly   \n",
       "18                                    yao   \n",
       "19                         graphql-engine   \n",
       "20                            preserve-cd   \n",
       "21                             plasticity   \n",
       "22                          advanced-java   \n",
       "23  Anime-Girls-Holding-Programming-Books   \n",
       "24                        leetcode-master   \n",
       "\n",
       "                               Repository description  Contributors count  \\\n",
       "0           京东自动下单 (自动登录,指定时间预约商品,商品补货监控,自动加购物车,自动下单)                   2   \n",
       "1   Security vulnerability database inclusive of C...                   3   \n",
       "2   Real-time performance monitoring, done right! ...                   5   \n",
       "3   A multi core friendly rigid body physics and c...                   3   \n",
       "4          Autonomous flight system for aerial robots                   5   \n",
       "5   💻📖对开发人员有用的定律、理论、原则和模式。(Laws, Theories, Princip...                   5   \n",
       "6   List of ngrok alternatives and other ngrok-lik...                   5   \n",
       "7   刷算法全靠套路，认准 labuladong 就够了！English version supp...                   5   \n",
       "8             Fig adds autocomplete to your terminal.                   5   \n",
       "9   openpilot is an open source driver assistance ...                   5   \n",
       "10  A simple message board for your organization o...                   5   \n",
       "11  🍰 Desktop utility to download images/videos/mu...                   5   \n",
       "12                   Voron 2 CoreXY 3D Printer design                   5   \n",
       "13  🌈 An enterprise-class UI components based on A...                   5   \n",
       "14                                                  -                   1   \n",
       "15  FastAPI framework, high performance, easy to l...                   5   \n",
       "16                                      快速高效搭建可视化拖拽平台                   5   \n",
       "17  An open-source C++ library developed and used ...                   5   \n",
       "18  Yao A low code engine to create web services a...                   2   \n",
       "19  Blazing fast, instant realtime GraphQL APIs on...                   5   \n",
       "20                          Game Preservation Project                   2   \n",
       "21                                                  -                   3   \n",
       "22  😮 Core Interview Questions & Answers For Exper...                   5   \n",
       "23              Anime Girls Holding Programming Books                   5   \n",
       "24  《代码随想录》LeetCode 刷题攻略：200道经典题目刷题顺序，共60w字的详细图解，视...                   5   \n",
       "\n",
       "   Language used  \n",
       "0         Python  \n",
       "1              -  \n",
       "2              C  \n",
       "3            C++  \n",
       "4            C++  \n",
       "5              -  \n",
       "6              -  \n",
       "7       Markdown  \n",
       "8     TypeScript  \n",
       "9         Python  \n",
       "10    TypeScript  \n",
       "11        Python  \n",
       "12             -  \n",
       "13           Vue  \n",
       "14            C#  \n",
       "15        Python  \n",
       "16    TypeScript  \n",
       "17           C++  \n",
       "18            Go  \n",
       "19       Haskell  \n",
       "20             -  \n",
       "21    TypeScript  \n",
       "22          Java  \n",
       "23             -  \n",
       "24             -  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\"Repository title\":rep_title,\"Repository description\":rep_desc,\"Contributors count\":contri_counts,\n",
    "                   \"Language used\":langs_used})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## creating the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Trending Github topics\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q6)Scrape the details of top 100 songs on billiboard.com.\n",
    "\n",
    "Url = https:/www.billboard.com/\n",
    "\n",
    "You have to find the following details:\n",
    "\n",
    "A) Song name\n",
    "\n",
    "B) Artist name\n",
    "\n",
    "C) Last week rank\n",
    "\n",
    "D) Peak rank\n",
    "\n",
    "E) Weeks on board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#site url\n",
    "url = 'https://www.billboard.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking on 'Charts' option\n",
    "charts = driver.find_element_by_xpath('/html/body/div[4]/header/div[1]/div/div/div[2]/div/nav/ul/li[1]/a')\n",
    "\n",
    "charts.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking on 'Hot 100' option\n",
    "H_100 = driver.find_element_by_xpath('/html/body/div[4]/header/div[2]/div/nav/ul/li[1]/a')\n",
    "\n",
    "H_100.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the source content of web page\n",
    "soup = BeautifulSoup(driver.page_source,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = soup.find_all('ul',{'class':'lrv-a-unstyle-list lrv-u-flex lrv-u-height-100p lrv-u-flex-direction-column@mobile-max'})\n",
    "\n",
    "result = [i.text.strip().split(\"\\n\") for i in result]\n",
    "\n",
    "\n",
    "#for song name\n",
    "song = [i[0] for i in result]\n",
    "\n",
    "#for artist name\n",
    "artist = [i[3] for i in result]\n",
    "\n",
    "#for Last week rank and Weeks on board\n",
    "result_last = soup.find_all('li',{'class':'o-chart-results-list__item // a-chart-color u-width-72 u-width-55@mobile-max u-width-55@tablet-only lrv-u-flex lrv-u-flex-shrink-0 lrv-u-align-items-center lrv-u-justify-content-center lrv-u-border-b-1 u-border-b-0@mobile-max lrv-u-border-color-grey-light u-background-color-white-064@mobile-max u-hidden@mobile-max'})\n",
    "\n",
    "l_week_rank = [i.text.strip() for i in result_last[:-1:2]]\n",
    "\n",
    "weeks_on_b = [i.text.strip() for i in result_last[1::2]]\n",
    "\n",
    "#for Peak rank\n",
    "result_peak_rank = soup.find_all('li',{'o-chart-results-list__item // a-chart-bg-color a-chart-color u-width-72 u-width-55@mobile-max u-width-55@tablet-only lrv-u-flex lrv-u-flex-shrink-0 lrv-u-align-items-center lrv-u-justify-content-center lrv-u-background-color-grey-lightest lrv-u-border-b-1 u-border-b-0@mobile-max lrv-u-border-color-grey-light u-hidden@mobile-max'})\n",
    "peak_rank = [i.text.strip() for i in result_peak_rank[1::2]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## creating the Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song name</th>\n",
       "      <th>Artist name</th>\n",
       "      <th>Last week Rank</th>\n",
       "      <th>Peak Rank</th>\n",
       "      <th>Weeks on Board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We Don't Talk About Bruno</td>\n",
       "      <td>Carolina Gaitan, Mauro Castillo, Adassa, Rhenz...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Heat Waves</td>\n",
       "      <td>Glass Animals</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Easy On Me</td>\n",
       "      <td>Adele</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abcdefu</td>\n",
       "      <td>GAYLE</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stay</td>\n",
       "      <td>The Kid LAROI &amp; Justin Bieber</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>All Too Well (Taylor's Version)</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>84</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Come Back As A Country Boy</td>\n",
       "      <td>Blake Shelton</td>\n",
       "      <td>89</td>\n",
       "      <td>85</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Iffy</td>\n",
       "      <td>Chris Brown</td>\n",
       "      <td>96</td>\n",
       "      <td>71</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Home Sweet</td>\n",
       "      <td>Russell Dickerson</td>\n",
       "      <td>94</td>\n",
       "      <td>88</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Too Easy</td>\n",
       "      <td>Gunna &amp; Future</td>\n",
       "      <td>92</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Song name  \\\n",
       "0         We Don't Talk About Bruno   \n",
       "1                        Heat Waves   \n",
       "2                        Easy On Me   \n",
       "3                           abcdefu   \n",
       "4                              Stay   \n",
       "..                              ...   \n",
       "95  All Too Well (Taylor's Version)   \n",
       "96       Come Back As A Country Boy   \n",
       "97                             Iffy   \n",
       "98                       Home Sweet   \n",
       "99                         Too Easy   \n",
       "\n",
       "                                          Artist name Last week Rank  \\\n",
       "0   Carolina Gaitan, Mauro Castillo, Adassa, Rhenz...              1   \n",
       "1                                       Glass Animals              4   \n",
       "2                                               Adele              3   \n",
       "3                                               GAYLE              7   \n",
       "4                       The Kid LAROI & Justin Bieber              5   \n",
       "..                                                ...            ...   \n",
       "95                                       Taylor Swift             84   \n",
       "96                                      Blake Shelton             89   \n",
       "97                                        Chris Brown             96   \n",
       "98                                  Russell Dickerson             94   \n",
       "99                                     Gunna & Future             92   \n",
       "\n",
       "   Peak Rank Weeks on Board  \n",
       "0          1              8  \n",
       "1          2             57  \n",
       "2          1             19  \n",
       "3          4             13  \n",
       "4          1             32  \n",
       "..       ...            ...  \n",
       "95         1             14  \n",
       "96        85              5  \n",
       "97        71              5  \n",
       "98        88              5  \n",
       "99        16             16  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\"Song name\":song,\"Artist name\":artist,\"Last week Rank\":l_week_rank,\n",
    "                   \"Peak Rank\":peak_rank,'Weeks on Board':weeks_on_b})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Billboard top 100 songs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q8)Scrape the details of Highest selling novels.\n",
    "\n",
    "Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\n",
    "\n",
    "You have to find the following details:\n",
    "\n",
    "A) Book name\n",
    "\n",
    "B) Author name\n",
    "\n",
    "C) Volumes sold\n",
    "\n",
    "D) Publisher\n",
    "\n",
    "E) Genre\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#site url\n",
    "url = 'https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the source content of web page\n",
    "soup = BeautifulSoup(driver.page_source,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = soup.find_all('tbody')\n",
    "\n",
    "result = [i.text.strip().split(\"\\n\") for i in result]\n",
    "\n",
    "#for book name\n",
    "b_name = [j for i in result for j in i[1::8]]\n",
    "\n",
    "#for author name\n",
    "A_name = [j for i in result for j in i[2::8]]\n",
    "\n",
    "#for Volume sales\n",
    "V_sales = [j for i in result for j in i[3::8]]\n",
    "\n",
    "#for publisher info\n",
    "p_info = [j for i in result for j in i[4::8]]\n",
    "\n",
    "#for genre info\n",
    "Genre = [j for i in result for j in i[5::8]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book name</th>\n",
       "      <th>Artist name</th>\n",
       "      <th>Volume sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the ...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to ...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book name         Artist name  \\\n",
       "0                                  Da Vinci Code,The          Brown, Dan    \n",
       "1               Harry Potter and the Deathly Hallows       Rowling, J.K.    \n",
       "2           Harry Potter and the Philosopher's Stone       Rowling, J.K.    \n",
       "3          Harry Potter and the Order of the Phoenix       Rowling, J.K.    \n",
       "4                               Fifty Shades of Grey        James, E. L.    \n",
       "..                                                ...                 ...   \n",
       "95                                         Ghost,The      Harris, Robert    \n",
       "96                    Happy Days with the Naked Chef       Oliver, Jamie    \n",
       "97             Hunger Games,The:Hunger Games Trilogy    Collins, Suzanne    \n",
       "98   Lost Boy,The:A Foster Child's Search for the ...       Pelzer, Dave    \n",
       "99   Jamie's Ministry of Food:Anyone Can Learn to ...      Oliver, Jamie    \n",
       "\n",
       "    Volume sold          Publisher                          Genre  \n",
       "0    5,094,805         Transworld    Crime, Thriller & Adventure   \n",
       "1    4,475,152         Bloomsbury             Children's Fiction   \n",
       "2    4,200,654         Bloomsbury             Children's Fiction   \n",
       "3    4,179,479         Bloomsbury             Children's Fiction   \n",
       "4    3,758,936       Random House                Romance & Sagas   \n",
       "..          ...                ...                            ...  \n",
       "95     807,311       Random House     General & Literary Fiction   \n",
       "96     794,201            Penguin          Food & Drink: General   \n",
       "97     792,187    Scholastic Ltd.            Young Adult Fiction   \n",
       "98     791,507              Orion             Biography: General   \n",
       "99     791,095            Penguin           Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\"Book name\":b_name,\"Artist name\":A_name,\"Volume sold\":V_sales,\n",
    "                   \"Publisher\":p_info,'Genre':Genre})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"best selling books all time fifty shades grey\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q9)Scrape the details most watched tv series of all time from imdb.com.\n",
    "\n",
    "Url = https://www.imdb.com/list/ls095964455/\n",
    "\n",
    "You have to find the following details:\n",
    "\n",
    "A) Name\n",
    "\n",
    "B) Year span\n",
    "\n",
    "C) Genre\n",
    "\n",
    "D) Run time\n",
    "\n",
    "E) Ratings\n",
    "\n",
    "F) Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#site url\n",
    "url = 'https://www.imdb.com/list/ls095964455/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the source content of web page\n",
    "soup = BeautifulSoup(driver.page_source,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = soup.find_all('div',{'class':'lister-item-content'})\n",
    "\n",
    "#for tv series name\n",
    "series_name = []\n",
    "for i in result:\n",
    "    result_h = i.find('a')\n",
    "    series_name.append(result_h.text)\n",
    "\n",
    "#for year span\n",
    "year_span = []\n",
    "for i in result:\n",
    "    result_h = i.find('span',{'class':'lister-item-index unbold text-primary'})\n",
    "    year_span.append(result_h.text.strip())\n",
    "\n",
    "#for genre info\n",
    "Genre = []\n",
    "for i in result:\n",
    "    result_h = i.find('span',{'class':'genre'})\n",
    "    Genre.append(result_h.text.strip())\n",
    "\n",
    "#for runtime info\n",
    "run_time = []\n",
    "for i in result:\n",
    "    result_h = i.find('span',{'class':'runtime'})\n",
    "    run_time.append(result_h.text.strip())\n",
    "\n",
    "#for Ratings\n",
    "ratings = []\n",
    "for i in result:\n",
    "    result_h = i.find('div',{'class':'ipl-rating-star small'})\n",
    "    ratings.append(result_h.text.strip())\n",
    "\n",
    "#for Votes info\n",
    "votes = []\n",
    "for i in result:\n",
    "    result_h = i.find('span',{'name':'nv'})\n",
    "    votes.append(result_h.text.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>1.</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>1,956,983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>2.</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>966,681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>3.</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>932,184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>4.</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>279,090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>5.</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>239,270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>96.</td>\n",
       "      <td>Drama, Fantasy</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>47,813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>97.</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>58,534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>98.</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>185,818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>99.</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7.1</td>\n",
       "      <td>39,342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>100.</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>222,123</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name Year span                     Genre  \\\n",
       "0                  Game of Thrones        1.  Action, Adventure, Drama   \n",
       "1                  Stranger Things        2.    Drama, Fantasy, Horror   \n",
       "2                 The Walking Dead        3.   Drama, Horror, Thriller   \n",
       "3                   13 Reasons Why        4.  Drama, Mystery, Thriller   \n",
       "4                          The 100        5.    Drama, Mystery, Sci-Fi   \n",
       "..                             ...       ...                       ...   \n",
       "95                           Reign       96.            Drama, Fantasy   \n",
       "96  A Series of Unfortunate Events       97.  Adventure, Comedy, Drama   \n",
       "97                  Criminal Minds       98.     Crime, Drama, Mystery   \n",
       "98           Scream: The TV Series       99.      Comedy, Crime, Drama   \n",
       "99      The Haunting of Hill House      100.    Drama, Horror, Mystery   \n",
       "\n",
       "    Runtime Ratings      Votes  \n",
       "0    57 min     9.2  1,956,983  \n",
       "1    51 min     8.7    966,681  \n",
       "2    44 min     8.1    932,184  \n",
       "3    60 min     7.5    279,090  \n",
       "4    43 min     7.6    239,270  \n",
       "..      ...     ...        ...  \n",
       "95   42 min     7.5     47,813  \n",
       "96   50 min     7.8     58,534  \n",
       "97   42 min     8.1    185,818  \n",
       "98   45 min     7.1     39,342  \n",
       "99  572 min     8.6    222,123  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\"Name\":series_name,\"Year span\":year_span,\"Genre\":Genre,\n",
    "                   \"Runtime\":run_time,'Ratings':ratings,\"Votes\":votes})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Top 100 most watched tv shows of all time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q10). Details of Datasets from UCI machine learning repositories.\n",
    "\n",
    "Url = https://archive.ics.uci.edu/\n",
    "\n",
    "You have to find the following details:\n",
    "\n",
    "A) Dataset name\n",
    "\n",
    "B) Data type\n",
    "\n",
    "C) Task\n",
    "\n",
    "D) Attribute type\n",
    "\n",
    "E) No of instances\n",
    "\n",
    "F) No of attribute\n",
    "\n",
    "G) Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#site url\n",
    "url = 'https://archive.ics.uci.edu/ml/index.php'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking on 'view all datasets' option\n",
    "view_all_datasets = driver.find_element_by_xpath('/html/body/table[1]/tbody/tr/td[2]/span[2]/a/font/b')\n",
    "\n",
    "view_all_datasets.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the source content of web page\n",
    "soup = BeautifulSoup(driver.page_source,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = soup.find_all('tr')\n",
    "result = [i.text.strip().replace(\"\\xa0\",' ').split(\"\\n\") for i in result[19:-1:2]] \n",
    "\n",
    "#for dataset name\n",
    "d_name = [i[0] for i in result]\n",
    "\n",
    "#for datatype\n",
    "\n",
    "datatype = []\n",
    "for i in result:\n",
    "    try:\n",
    "        if i[2] == ' ':\n",
    "            datatype.append('-')           #filling up empty strings with '-'\n",
    "        else:\n",
    "            datatype.append(i[2])\n",
    "    except:\n",
    "        datatype.append(\"-\")\n",
    "        \n",
    "#for task\n",
    "task = []\n",
    "for i in result:\n",
    "    try:\n",
    "        if i[3] == ' ':\n",
    "            task.append('-')           #filling up empty strings with '-'\n",
    "        else:\n",
    "            task.append(i[3])\n",
    "    except:\n",
    "        task.append(\"-\")\n",
    "\n",
    "#for attribute types\n",
    "attribute_types = []\n",
    "for i in result:\n",
    "    try:\n",
    "        if i[4] == ' ':\n",
    "            attribute_types.append('-')           #filling up empty strings with '-'\n",
    "        else:\n",
    "            attribute_types.append(i[4])\n",
    "    except:\n",
    "        attribute_types.append(\"-\")\n",
    "\n",
    "#for No. of instances\n",
    "No_of_instances = []\n",
    "for i in result:\n",
    "    try:\n",
    "        if i[5] == ' ':\n",
    "            No_of_instances.append('-')           #filling up empty strings with '-'\n",
    "        else:\n",
    "            No_of_instances.append(i[5])\n",
    "    except:\n",
    "        No_of_instances.append(\"-\")\n",
    "\n",
    "#for no.of attributes\n",
    "No_of_attributes = []\n",
    "for i in result:\n",
    "    try:\n",
    "        if i[6] == ' ':\n",
    "            No_of_attributes.append('-')           #filling up empty strings with '-'\n",
    "        else:\n",
    "            No_of_attributes.append(i[6])\n",
    "    except:\n",
    "        No_of_attributes.append(\"-\")\n",
    "\n",
    "#for year info\n",
    "year = []\n",
    "for i in result:\n",
    "    try:\n",
    "        if i[7] == ' ':\n",
    "            year.append('-')           #filling up empty strings with '-'\n",
    "        else:\n",
    "            year.append(i[7])\n",
    "    except:\n",
    "        year.append(\"-\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset Name</th>\n",
       "      <th>Data types</th>\n",
       "      <th>Default task</th>\n",
       "      <th>Attribute types</th>\n",
       "      <th>No. of Instances</th>\n",
       "      <th>No. of Attributes</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abalone</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>4177</td>\n",
       "      <td>8</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48842</td>\n",
       "      <td>14</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annealing</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>798</td>\n",
       "      <td>38</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anonymous Microsoft Web Data</td>\n",
       "      <td>-</td>\n",
       "      <td>Recommender-Systems</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>37711</td>\n",
       "      <td>294</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arrhythmia</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>452</td>\n",
       "      <td>279</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>Influenza outbreak event prediction via Twitte...</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>75840</td>\n",
       "      <td>525</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>Turkish Music Emotion Dataset</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>400</td>\n",
       "      <td>50</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>Maternal Health Risk Data Set</td>\n",
       "      <td>-</td>\n",
       "      <td>Classification</td>\n",
       "      <td>-</td>\n",
       "      <td>1014</td>\n",
       "      <td>7</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>Room Occupancy Estimation</td>\n",
       "      <td>Multivariate, Time-Series</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>10129</td>\n",
       "      <td>16</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>Image Recognition Task Execution Times in Mobi...</td>\n",
       "      <td>Univariate</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>4000</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>622 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Dataset Name  \\\n",
       "0                                              Abalone   \n",
       "1                                                Adult   \n",
       "2                                            Annealing   \n",
       "3                         Anonymous Microsoft Web Data   \n",
       "4                                           Arrhythmia   \n",
       "..                                                 ...   \n",
       "617  Influenza outbreak event prediction via Twitte...   \n",
       "618                      Turkish Music Emotion Dataset   \n",
       "619                      Maternal Health Risk Data Set   \n",
       "620                          Room Occupancy Estimation   \n",
       "621  Image Recognition Task Execution Times in Mobi...   \n",
       "\n",
       "                     Data types          Default task  \\\n",
       "0                 Multivariate        Classification    \n",
       "1                 Multivariate        Classification    \n",
       "2                 Multivariate        Classification    \n",
       "3                             -  Recommender-Systems    \n",
       "4                 Multivariate        Classification    \n",
       "..                          ...                   ...   \n",
       "617               Multivariate        Classification    \n",
       "618               Multivariate        Classification    \n",
       "619                           -       Classification    \n",
       "620  Multivariate, Time-Series        Classification    \n",
       "621                 Univariate            Regression    \n",
       "\n",
       "                 Attribute types No. of Instances No. of Attributes  Year  \n",
       "0    Categorical, Integer, Real             4177                 8   1995  \n",
       "1          Categorical, Integer            48842                14   1996  \n",
       "2    Categorical, Integer, Real              798                 38     -  \n",
       "3                   Categorical            37711               294   1998  \n",
       "4    Categorical, Integer, Real              452               279   1998  \n",
       "..                           ...              ...               ...   ...  \n",
       "617               Integer, Real            75840               525   2020  \n",
       "618               Integer, Real              400                50   2020  \n",
       "619                            -            1014                 7   2020  \n",
       "620                        Real            10129                16   2021  \n",
       "621                        Real             4000                 2   2021  \n",
       "\n",
       "[622 rows x 7 columns]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\"Dataset Name\":d_name,\"Data types\":datatype,\"Default task\":task,\n",
    "                   \"Attribute types\":attribute_types,'No. of Instances':No_of_instances,\n",
    "                   \"No. of Attributes\":No_of_attributes,\"Year\":year})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Details of ML datasets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## --------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q7)Scrape the details of Data science recruiters from naukri.com.\n",
    "\n",
    "Url = https://www.naukri.com/\n",
    "\n",
    "You have to find the following details:\n",
    "\n",
    "A) Name\n",
    "\n",
    "B) Designation\n",
    "\n",
    "C) Company\n",
    "\n",
    "D) Skills they hire for\n",
    "\n",
    "E) Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "#site url\n",
    "url = 'https://www.naukri.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get to the recruiters option\n",
    "\n",
    "get_to = driver.find_element_by_xpath('/html/body/div[1]/div[2]/div[1]/div/ul/li[1]/a/div')\n",
    "get_to.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to switch to newly opened tab\n",
    "\n",
    "driver.switch_to.window(driver.window_handles[1])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clicking on recruiters option\n",
    "\n",
    "recruiters_op = driver.find_element_by_xpath('/html/body/div[1]/div/ul/li[2]/a')\n",
    "recruiters_op.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "#again switchng it to newly opened tab \n",
    "\n",
    "driver.switch_to.window(driver.window_handles[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now to get web element of search bar\n",
    "\n",
    "search = driver.find_element_by_xpath('/html/body/div[2]/div[2]/div[1]/div[1]/form/div[1]/div/div[1]/div[1]/div[2]/input')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to enter as 'Data science' in search bar\n",
    "search.send_keys('Data science')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now searching for entered input\n",
    "\n",
    "to_search = driver.find_element_by_xpath('/html/body/div[2]/div[2]/div[1]/div[1]/form/div[1]/button')\n",
    "to_search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the source content of web page\n",
    "soup = BeautifulSoup(driver.page_source,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrapping name of recruiters only from first page(for first 50 results)\n",
    "name = soup.find_all('span',{'class':'fl ellipsis'})\n",
    "name = [i.text for i in name]\n",
    "\n",
    "#for Designation\n",
    "desig = soup.find_all('span',{'class':'ellipsis clr'})\n",
    "desig = [i.text for i in desig]\n",
    "\n",
    "#for company name\n",
    "company = soup.find_all('a',{'class':'ellipsis'})\n",
    "company = [i.text for i in company[1::2]]\n",
    "\n",
    "#for skills\n",
    "skills = soup.find_all('span',{'class':'ellipsis clr'})\n",
    "skills = [i.text for i in skills]\n",
    "\n",
    "#for location\n",
    "location = soup.find_all('div',{'class':'hireSec highlightable'})\n",
    "location = [i.text for i in location]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Designation</th>\n",
       "      <th>Company</th>\n",
       "      <th>Skills required</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aakash Harit</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>Data Science Network</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>Classic ASP Developer,   Internet Marketin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shravan Kumar Gaddam</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>Shore Infotech India Pvt. Ltd</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>.Net,   Java,   Data Science,   Linux Admi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MARSIAN Technologies LLP</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>MARSIAN Technologies LLP</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>Data Science,   Artificial Intelligence,  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anik Agrawal</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>Enerlytics Software Solutions Pvt Ltd</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>Mean Stack,   javascript,   angularjs,   m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>subhas patel</td>\n",
       "      <td>Founder CEO</td>\n",
       "      <td>LibraryXProject</td>\n",
       "      <td>Founder CEO</td>\n",
       "      <td>Hadoop,   Spark,   Digital Strategy,   Dat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Abhishek - Only Analytics Hiring - India and</td>\n",
       "      <td>Recruitment Lead Consultant</td>\n",
       "      <td>Apidel Technologies Division of Transpower</td>\n",
       "      <td>Recruitment Lead Consultant</td>\n",
       "      <td>Analytics,   Business Intelligence,   Busi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Institute for Financial Management and Resear</td>\n",
       "      <td>Programme Manager</td>\n",
       "      <td>IFMR</td>\n",
       "      <td>Programme Manager</td>\n",
       "      <td>Data Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Balu Ramesh</td>\n",
       "      <td>HR Administrator</td>\n",
       "      <td>Techvantage Systems Pvt Ltd</td>\n",
       "      <td>HR Administrator</td>\n",
       "      <td>Machine Learning,   algorithms,   Go Gette...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Asif Lucknowi</td>\n",
       "      <td>Director</td>\n",
       "      <td>Weupskill- Live Wire India</td>\n",
       "      <td>Director</td>\n",
       "      <td>Technical Training,   Software Development...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>InstaFinancials</td>\n",
       "      <td>Human Resource</td>\n",
       "      <td>CBL Data Science Private Limited</td>\n",
       "      <td>Human Resource</td>\n",
       "      <td>Software Development,   It Sales,   Accoun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Priyanka Akiri</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>Infinitive Software Solutions</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>Oracle Dba,   Data Science,   Data Warehou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Kalpana Dumpala</td>\n",
       "      <td>Executive Hiring</td>\n",
       "      <td>Innominds Software</td>\n",
       "      <td>Executive Hiring</td>\n",
       "      <td>Qa,   Ui/ux,   Java Developer,   Java Arch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Mubarak</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>MoneyTap</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>Business Intelligence,   Data Warehousing,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Kushal Rastogi</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>QuantMagnum Technologies Pvt. Ltd.</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>Office Administration,   Hr Administration...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Mahesh Babu Channa</td>\n",
       "      <td>HR Team Lead</td>\n",
       "      <td>SocialPrachar.com</td>\n",
       "      <td>HR Team Lead</td>\n",
       "      <td>Social Media,   digital media maketing,   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Sakshi Chhikara</td>\n",
       "      <td>Assistant Manager HR</td>\n",
       "      <td>BIZ INFOTECNO PRIVATE LIMITED</td>\n",
       "      <td>Assistant Manager HR</td>\n",
       "      <td>React.js,   Data Science,   Java,   Front ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Kapil Devang</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>BISP Solutions</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>Big Data,   Hadoop,   Data Analytics,   Da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Ruchi Dhote</td>\n",
       "      <td>Senior Executive Talent Acquisition</td>\n",
       "      <td>Bristlecone India Ltd</td>\n",
       "      <td>Senior Executive Talent Acquisition</td>\n",
       "      <td>Qlikview,   Qlik Sense,   Microsoft Azure,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Sandhya Khandagale</td>\n",
       "      <td>HR Recruiter</td>\n",
       "      <td>Compumatrice Multimedia Pvt Ltd</td>\n",
       "      <td>HR Recruiter</td>\n",
       "      <td>Big Data,   Data Science,   Artificial Int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Manisha Yadav</td>\n",
       "      <td>HR Executive</td>\n",
       "      <td>Easi Tax</td>\n",
       "      <td>HR Executive</td>\n",
       "      <td>Telecalling,   Client Interaction,   Marke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Riya Rajesh</td>\n",
       "      <td>Manager Talent Acquisition</td>\n",
       "      <td>Novelworx Digital Solutions</td>\n",
       "      <td>Manager Talent Acquisition</td>\n",
       "      <td>Data Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Rashmi Bhattacharjee</td>\n",
       "      <td>HR Head</td>\n",
       "      <td>AXESTRACK SOFTWARE SOLUTIONS PRIVATE...</td>\n",
       "      <td>HR Head</td>\n",
       "      <td>Corporate Sales,   Software Development,  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Faizan Kareem</td>\n",
       "      <td>HR MANAGER</td>\n",
       "      <td>FirstTech Consaltants Pvt.Ltd</td>\n",
       "      <td>HR MANAGER</td>\n",
       "      <td>Data Analytics,   Data Science,   Machine ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Rithika dadwal</td>\n",
       "      <td>HR Recruiter</td>\n",
       "      <td>Affine Analytics</td>\n",
       "      <td>HR Recruiter</td>\n",
       "      <td>Data Science,   Machine Learning,   Python...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Shaun Rao</td>\n",
       "      <td>Manager Human Resources</td>\n",
       "      <td>Exela Technologies</td>\n",
       "      <td>Manager Human Resources</td>\n",
       "      <td>Java,   Net,   Angularjs,   Hr,   Infrastr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Azahar Shaikh</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>NEAL ANALYTICS SERVICES PVT LTD</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>Data Science,   Artificial Intelligence,  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Manas</td>\n",
       "      <td>Lead Talent acquisition</td>\n",
       "      <td>Autumn Leaf Consulting Services Private...</td>\n",
       "      <td>Lead Talent acquisition</td>\n",
       "      <td>Software Architecture,   Vp Engineering,  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>kumar</td>\n",
       "      <td>Proprietor</td>\n",
       "      <td>trainin</td>\n",
       "      <td>Proprietor</td>\n",
       "      <td>Data Science,   Hadoop,   Rpas,   Devops, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Sunil Vedula</td>\n",
       "      <td>CEO</td>\n",
       "      <td>Nanoprecise Sci Corp</td>\n",
       "      <td>CEO</td>\n",
       "      <td>Signal Processing,   Machine Learning,   N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Rajat Kumar</td>\n",
       "      <td>Founder CEO</td>\n",
       "      <td>R.S Consultancy &amp;amp; Services</td>\n",
       "      <td>Founder CEO</td>\n",
       "      <td>Web Technologies,   Project Management,   ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Dhruv Dev Dubey</td>\n",
       "      <td>Company Recruitment Head</td>\n",
       "      <td>Confidential</td>\n",
       "      <td>Company Recruitment Head</td>\n",
       "      <td>Server Administartion,   Verilog,   Vhdl, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Avodha</td>\n",
       "      <td>Business Development Associate</td>\n",
       "      <td>Nikitha Palaparthi</td>\n",
       "      <td>Business Development Associate</td>\n",
       "      <td>Ethical Hacking,   Security Operations Cen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Jayanth N</td>\n",
       "      <td>Project Manager</td>\n",
       "      <td>Dollarbird Information Services Pvt, Ltd</td>\n",
       "      <td>Project Manager</td>\n",
       "      <td>Data Analytics,   Managed Services,   Team...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Priya Khare</td>\n",
       "      <td>Senior Manager</td>\n",
       "      <td>Independent Consultant</td>\n",
       "      <td>Senior Manager</td>\n",
       "      <td>Data Science,   Artificial Intelligence,  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Amit Sharma</td>\n",
       "      <td>Consultant</td>\n",
       "      <td>ASCO consulting</td>\n",
       "      <td>Consultant</td>\n",
       "      <td>Machine Learning,   Artificial Intelligenc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Kanan</td>\n",
       "      <td>senior technology instructor</td>\n",
       "      <td>NY INST</td>\n",
       "      <td>senior technology instructor</td>\n",
       "      <td>C,   C++,   Artificial Intelligence,   Pyt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Shashikant Chaudhary</td>\n",
       "      <td>HR Recruiter/HR Excutive</td>\n",
       "      <td>3D India Staffing Research &amp;amp; Consulting...</td>\n",
       "      <td>HR Recruiter/HR Excutive</td>\n",
       "      <td>Relationship Management,   Retail Sales,  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Brad</td>\n",
       "      <td>Manager, Technical Recruiting</td>\n",
       "      <td>O.C. Tanner</td>\n",
       "      <td>Manager, Technical Recruiting</td>\n",
       "      <td>Data Science,   Software Engineering</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Rutuja Pawar</td>\n",
       "      <td>Technical Recruiter</td>\n",
       "      <td>Demand Matrix</td>\n",
       "      <td>Technical Recruiter</td>\n",
       "      <td>Data Science,   Big Data Analytics,   Digi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Madhusudhan Sridhar</td>\n",
       "      <td>Erp Implementer</td>\n",
       "      <td>MADHUSUDHAN SRIDHAR</td>\n",
       "      <td>Erp Implementer</td>\n",
       "      <td>Data Science,   Recruitment,   Salary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Ankit Sinha</td>\n",
       "      <td>Head Analytics</td>\n",
       "      <td>Suntech Global</td>\n",
       "      <td>Head Analytics</td>\n",
       "      <td>B.Tech,   Tableau,   Statistics,   R,   An...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Gaurav Chouhan</td>\n",
       "      <td>Chief Technical Officer</td>\n",
       "      <td>Strategic Consulting Lab</td>\n",
       "      <td>Chief Technical Officer</td>\n",
       "      <td>Software Development,   Business Intellige...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Rashi Kacker</td>\n",
       "      <td>Sr Product Manager</td>\n",
       "      <td>Impel Labs Pvt. Ltd.</td>\n",
       "      <td>Sr Product Manager</td>\n",
       "      <td>Data Science,   Node.js,   Angularjs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Ashwini</td>\n",
       "      <td>Director Global Delivery</td>\n",
       "      <td>MRP Advisers</td>\n",
       "      <td>Director Global Delivery</td>\n",
       "      <td>Data Science,   Media Marketing,   Resourc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Balaji Kolli</td>\n",
       "      <td>Co Founder</td>\n",
       "      <td>Saras Solutions India Pvt Ltd</td>\n",
       "      <td>Co Founder</td>\n",
       "      <td>Data Analysis,   Learning,   Data Science,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Rajani Nagaraj</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>WildJasmine</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>Java,   Hadoop,   R,   Machine Learning,  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>ROHIT Kumar</td>\n",
       "      <td>Architect</td>\n",
       "      <td>LNT Private Limited</td>\n",
       "      <td>Architect</td>\n",
       "      <td>Software Development,   Core Java,   Unit ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Amir Chowdhury</td>\n",
       "      <td>Managing Partner</td>\n",
       "      <td>Granular.ai</td>\n",
       "      <td>Managing Partner</td>\n",
       "      <td>Machine Learning,   Data Science,   Produc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Radha Manivasagam</td>\n",
       "      <td>HR Executive</td>\n",
       "      <td>Techcovery</td>\n",
       "      <td>HR Executive</td>\n",
       "      <td>Python,   Artificial Intelligence,   Machi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>SREEDHAR</td>\n",
       "      <td>Recruitment Consultant</td>\n",
       "      <td>JOBSMILL BUSINESS SOLUTIONS PRIVATE LIMITED</td>\n",
       "      <td>Recruitment Consultant</td>\n",
       "      <td>Data Science,   Machine Learning,   Big Da...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Name  \\\n",
       "0                                    Aakash Harit   \n",
       "1                            shravan Kumar Gaddam   \n",
       "2                        MARSIAN Technologies LLP   \n",
       "3                                    Anik Agrawal   \n",
       "4                                    subhas patel   \n",
       "5   Abhishek - Only Analytics Hiring - India and    \n",
       "6   Institute for Financial Management and Resear   \n",
       "7                                     Balu Ramesh   \n",
       "8                                   Asif Lucknowi   \n",
       "9                                 InstaFinancials   \n",
       "10                                 Priyanka Akiri   \n",
       "11                                Kalpana Dumpala   \n",
       "12                                        Mubarak   \n",
       "13                                 Kushal Rastogi   \n",
       "14                             Mahesh Babu Channa   \n",
       "15                                Sakshi Chhikara   \n",
       "16                                   Kapil Devang   \n",
       "17                                    Ruchi Dhote   \n",
       "18                             Sandhya Khandagale   \n",
       "19                                  Manisha Yadav   \n",
       "20                                    Riya Rajesh   \n",
       "21                           Rashmi Bhattacharjee   \n",
       "22                                  Faizan Kareem   \n",
       "23                                 Rithika dadwal   \n",
       "24                                      Shaun Rao   \n",
       "25                                  Azahar Shaikh   \n",
       "26                                          Manas   \n",
       "27                                          kumar   \n",
       "28                                   Sunil Vedula   \n",
       "29                                    Rajat Kumar   \n",
       "30                                Dhruv Dev Dubey   \n",
       "31                                         Avodha   \n",
       "32                                      Jayanth N   \n",
       "33                                    Priya Khare   \n",
       "34                                    Amit Sharma   \n",
       "35                                          Kanan   \n",
       "36                           Shashikant Chaudhary   \n",
       "37                                           Brad   \n",
       "38                                   Rutuja Pawar   \n",
       "39                            Madhusudhan Sridhar   \n",
       "40                                    Ankit Sinha   \n",
       "41                                 Gaurav Chouhan   \n",
       "42                                   Rashi Kacker   \n",
       "43                                        Ashwini   \n",
       "44                                   Balaji Kolli   \n",
       "45                                 Rajani Nagaraj   \n",
       "46                                    ROHIT Kumar   \n",
       "47                                 Amir Chowdhury   \n",
       "48                              Radha Manivasagam   \n",
       "49                                       SREEDHAR   \n",
       "\n",
       "                            Designation  \\\n",
       "0                            HR Manager   \n",
       "1                     Company Recruiter   \n",
       "2                            Company HR   \n",
       "3                     Company Recruiter   \n",
       "4                           Founder CEO   \n",
       "5           Recruitment Lead Consultant   \n",
       "6                     Programme Manager   \n",
       "7                      HR Administrator   \n",
       "8                              Director   \n",
       "9                        Human Resource   \n",
       "10                           HR Manager   \n",
       "11                     Executive Hiring   \n",
       "12                           Company HR   \n",
       "13                           Company HR   \n",
       "14                         HR Team Lead   \n",
       "15                 Assistant Manager HR   \n",
       "16                           HR Manager   \n",
       "17  Senior Executive Talent Acquisition   \n",
       "18                         HR Recruiter   \n",
       "19                         HR Executive   \n",
       "20           Manager Talent Acquisition   \n",
       "21                              HR Head   \n",
       "22                           HR MANAGER   \n",
       "23                         HR Recruiter   \n",
       "24              Manager Human Resources   \n",
       "25                    Company Recruiter   \n",
       "26              Lead Talent acquisition   \n",
       "27                           Proprietor   \n",
       "28                                  CEO   \n",
       "29                          Founder CEO   \n",
       "30             Company Recruitment Head   \n",
       "31       Business Development Associate   \n",
       "32                      Project Manager   \n",
       "33                       Senior Manager   \n",
       "34                           Consultant   \n",
       "35         senior technology instructor   \n",
       "36             HR Recruiter/HR Excutive   \n",
       "37        Manager, Technical Recruiting   \n",
       "38                  Technical Recruiter   \n",
       "39                      Erp Implementer   \n",
       "40                       Head Analytics   \n",
       "41              Chief Technical Officer   \n",
       "42                   Sr Product Manager   \n",
       "43             Director Global Delivery   \n",
       "44                           Co Founder   \n",
       "45                           HR Manager   \n",
       "46                            Architect   \n",
       "47                     Managing Partner   \n",
       "48                         HR Executive   \n",
       "49               Recruitment Consultant   \n",
       "\n",
       "                                           Company  \\\n",
       "0                             Data Science Network   \n",
       "1                    Shore Infotech India Pvt. Ltd   \n",
       "2                         MARSIAN Technologies LLP   \n",
       "3            Enerlytics Software Solutions Pvt Ltd   \n",
       "4                                  LibraryXProject   \n",
       "5       Apidel Technologies Division of Transpower   \n",
       "6                                             IFMR   \n",
       "7                      Techvantage Systems Pvt Ltd   \n",
       "8                       Weupskill- Live Wire India   \n",
       "9                 CBL Data Science Private Limited   \n",
       "10                   Infinitive Software Solutions   \n",
       "11                              Innominds Software   \n",
       "12                                        MoneyTap   \n",
       "13              QuantMagnum Technologies Pvt. Ltd.   \n",
       "14                               SocialPrachar.com   \n",
       "15                   BIZ INFOTECNO PRIVATE LIMITED   \n",
       "16                                  BISP Solutions   \n",
       "17                           Bristlecone India Ltd   \n",
       "18                 Compumatrice Multimedia Pvt Ltd   \n",
       "19                                        Easi Tax   \n",
       "20                     Novelworx Digital Solutions   \n",
       "21         AXESTRACK SOFTWARE SOLUTIONS PRIVATE...   \n",
       "22                   FirstTech Consaltants Pvt.Ltd   \n",
       "23                                Affine Analytics   \n",
       "24                              Exela Technologies   \n",
       "25                 NEAL ANALYTICS SERVICES PVT LTD   \n",
       "26      Autumn Leaf Consulting Services Private...   \n",
       "27                                         trainin   \n",
       "28                            Nanoprecise Sci Corp   \n",
       "29                  R.S Consultancy &amp; Services   \n",
       "30                                    Confidential   \n",
       "31                              Nikitha Palaparthi   \n",
       "32        Dollarbird Information Services Pvt, Ltd   \n",
       "33                          Independent Consultant   \n",
       "34                                 ASCO consulting   \n",
       "35                                         NY INST   \n",
       "36  3D India Staffing Research &amp; Consulting...   \n",
       "37                                     O.C. Tanner   \n",
       "38                                   Demand Matrix   \n",
       "39                             MADHUSUDHAN SRIDHAR   \n",
       "40                                  Suntech Global   \n",
       "41                        Strategic Consulting Lab   \n",
       "42                            Impel Labs Pvt. Ltd.   \n",
       "43                                    MRP Advisers   \n",
       "44                   Saras Solutions India Pvt Ltd   \n",
       "45                                     WildJasmine   \n",
       "46                             LNT Private Limited   \n",
       "47                                     Granular.ai   \n",
       "48                                      Techcovery   \n",
       "49     JOBSMILL BUSINESS SOLUTIONS PRIVATE LIMITED   \n",
       "\n",
       "                        Skills required  \\\n",
       "0                            HR Manager   \n",
       "1                     Company Recruiter   \n",
       "2                            Company HR   \n",
       "3                     Company Recruiter   \n",
       "4                           Founder CEO   \n",
       "5           Recruitment Lead Consultant   \n",
       "6                     Programme Manager   \n",
       "7                      HR Administrator   \n",
       "8                              Director   \n",
       "9                        Human Resource   \n",
       "10                           HR Manager   \n",
       "11                     Executive Hiring   \n",
       "12                           Company HR   \n",
       "13                           Company HR   \n",
       "14                         HR Team Lead   \n",
       "15                 Assistant Manager HR   \n",
       "16                           HR Manager   \n",
       "17  Senior Executive Talent Acquisition   \n",
       "18                         HR Recruiter   \n",
       "19                         HR Executive   \n",
       "20           Manager Talent Acquisition   \n",
       "21                              HR Head   \n",
       "22                           HR MANAGER   \n",
       "23                         HR Recruiter   \n",
       "24              Manager Human Resources   \n",
       "25                    Company Recruiter   \n",
       "26              Lead Talent acquisition   \n",
       "27                           Proprietor   \n",
       "28                                  CEO   \n",
       "29                          Founder CEO   \n",
       "30             Company Recruitment Head   \n",
       "31       Business Development Associate   \n",
       "32                      Project Manager   \n",
       "33                       Senior Manager   \n",
       "34                           Consultant   \n",
       "35         senior technology instructor   \n",
       "36             HR Recruiter/HR Excutive   \n",
       "37        Manager, Technical Recruiting   \n",
       "38                  Technical Recruiter   \n",
       "39                      Erp Implementer   \n",
       "40                       Head Analytics   \n",
       "41              Chief Technical Officer   \n",
       "42                   Sr Product Manager   \n",
       "43             Director Global Delivery   \n",
       "44                           Co Founder   \n",
       "45                           HR Manager   \n",
       "46                            Architect   \n",
       "47                     Managing Partner   \n",
       "48                         HR Executive   \n",
       "49               Recruitment Consultant   \n",
       "\n",
       "                                             Location  \n",
       "0       Classic ASP Developer,   Internet Marketin...  \n",
       "1       .Net,   Java,   Data Science,   Linux Admi...  \n",
       "2       Data Science,   Artificial Intelligence,  ...  \n",
       "3       Mean Stack,   javascript,   angularjs,   m...  \n",
       "4       Hadoop,   Spark,   Digital Strategy,   Dat...  \n",
       "5       Analytics,   Business Intelligence,   Busi...  \n",
       "6                                    Data Science      \n",
       "7       Machine Learning,   algorithms,   Go Gette...  \n",
       "8       Technical Training,   Software Development...  \n",
       "9       Software Development,   It Sales,   Accoun...  \n",
       "10      Oracle Dba,   Data Science,   Data Warehou...  \n",
       "11      Qa,   Ui/ux,   Java Developer,   Java Arch...  \n",
       "12      Business Intelligence,   Data Warehousing,...  \n",
       "13      Office Administration,   Hr Administration...  \n",
       "14      Social Media,   digital media maketing,   ...  \n",
       "15      React.js,   Data Science,   Java,   Front ...  \n",
       "16      Big Data,   Hadoop,   Data Analytics,   Da...  \n",
       "17      Qlikview,   Qlik Sense,   Microsoft Azure,...  \n",
       "18      Big Data,   Data Science,   Artificial Int...  \n",
       "19      Telecalling,   Client Interaction,   Marke...  \n",
       "20                                   Data Science      \n",
       "21      Corporate Sales,   Software Development,  ...  \n",
       "22      Data Analytics,   Data Science,   Machine ...  \n",
       "23      Data Science,   Machine Learning,   Python...  \n",
       "24      Java,   Net,   Angularjs,   Hr,   Infrastr...  \n",
       "25      Data Science,   Artificial Intelligence,  ...  \n",
       "26      Software Architecture,   Vp Engineering,  ...  \n",
       "27      Data Science,   Hadoop,   Rpas,   Devops, ...  \n",
       "28      Signal Processing,   Machine Learning,   N...  \n",
       "29      Web Technologies,   Project Management,   ...  \n",
       "30      Server Administartion,   Verilog,   Vhdl, ...  \n",
       "31      Ethical Hacking,   Security Operations Cen...  \n",
       "32      Data Analytics,   Managed Services,   Team...  \n",
       "33      Data Science,   Artificial Intelligence,  ...  \n",
       "34      Machine Learning,   Artificial Intelligenc...  \n",
       "35      C,   C++,   Artificial Intelligence,   Pyt...  \n",
       "36      Relationship Management,   Retail Sales,  ...  \n",
       "37           Data Science,   Software Engineering      \n",
       "38      Data Science,   Big Data Analytics,   Digi...  \n",
       "39          Data Science,   Recruitment,   Salary      \n",
       "40      B.Tech,   Tableau,   Statistics,   R,   An...  \n",
       "41      Software Development,   Business Intellige...  \n",
       "42           Data Science,   Node.js,   Angularjs      \n",
       "43      Data Science,   Media Marketing,   Resourc...  \n",
       "44      Data Analysis,   Learning,   Data Science,...  \n",
       "45      Java,   Hadoop,   R,   Machine Learning,  ...  \n",
       "46      Software Development,   Core Java,   Unit ...  \n",
       "47      Machine Learning,   Data Science,   Produc...  \n",
       "48      Python,   Artificial Intelligence,   Machi...  \n",
       "49      Data Science,   Machine Learning,   Big Da...  "
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\"Name\":name,\"Designation\":desig,\"Company\":company,\"Skills required\":skills,\"Location\":location})\n",
    "df              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Data science recruiters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
