{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location and have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#impoerting required libraries\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connecting to a webdriver\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#site url\n",
    "url = 'https://www.naukri.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"e26b23ae1b65c3bc934ea66bf9617667\", element=\"f7dbc73d-63e8-4c40-baea-96509dfb829d\")>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#searching an web element for job search bar using id\n",
    "search_job = driver.find_element_by_id('qsb-keyword-sugg')\n",
    "search_job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now writing requied name on the search bar\n",
    "search_job.send_keys(\"Data Analyst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"e26b23ae1b65c3bc934ea66bf9617667\", element=\"e22270f9-d3f6-48e5-822a-dff268b5c208\")>"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#searching an web element for location search bar using absolute xpath\n",
    "search_location = driver.find_element_by_xpath(\"/html/body/div[1]/div[3]/div[2]/section/div/form/div[2]/div/div/div/div[1]/div[2]/input\")\n",
    "search_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "#writing \"Bangalore\" in location bar search\n",
    "search_location.send_keys(\"Bangalore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now for search button,we can get a web element for that using an absolute xpath\n",
    "search_button = driver.find_element_by_xpath(\"/html/body/div[1]/div[3]/div[2]/section/div/form/div[3]/button\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrapping of Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a)extracting the job title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting the web elements which consists of job titles.\n",
    "\n",
    "titles_tag = driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "\n",
    "#extracting first 10 titles\n",
    "titles_tag = titles_tag[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lead - Data Analyst / Scientist',\n",
       " 'Senior Data Analyst',\n",
       " 'Data Analyst',\n",
       " 'BUSINESS ANALYST -DATA SCIENCE-CONSUMER',\n",
       " 'Data Analyst',\n",
       " 'Senior Data Analyst - Supporting Audits',\n",
       " 'Data Analyst',\n",
       " 'Senior Data Analyst',\n",
       " 'Senior Data Analyst',\n",
       " 'Data Analyst']"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now extracting a text from those web elements\n",
    "\n",
    "job_title = [i.text for i in titles_tag]\n",
    "job_title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b)extracting the job loation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting the web elements which consists of job loaction.\n",
    "\n",
    "loc_tag = driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "\n",
    "#extracting first 10 titles\n",
    "loc_tag = loc_tag[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bengaluru/Bangalore',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru',\n",
       " 'Bangalore/Bengaluru']"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now extracting a text from those web elements\n",
    "\n",
    "job_loc = [i.text for i in loc_tag]\n",
    "job_loc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c)extracting the company name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting the web elements which consists of company name\n",
    "\n",
    "comp_tag = driver.find_elements_by_xpath('//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "\n",
    "#extracting first 10 company name\n",
    "comp_tag = comp_tag[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Axim Technologies',\n",
       " 'Schneider Electric',\n",
       " 'Snaphunt',\n",
       " 'BRIDGEi2i Analytics Solutions Private Limited',\n",
       " 'Jeeva Organic',\n",
       " 'Visa',\n",
       " 'Flipkart',\n",
       " 'Glance',\n",
       " 'Glance IT Solution',\n",
       " 'Novel Office']"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "company_name = [i.text for i in comp_tag]\n",
    "company_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d)extracting the exp required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting the web elements which consists of experience required\n",
    "\n",
    "exp_req = driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]')\n",
    "\n",
    "#extracting first 10 \n",
    "exp_req = exp_req[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['12-14 Yrs',\n",
       " '0-2 Yrs',\n",
       " '0-2 Yrs',\n",
       " '0-2 Yrs',\n",
       " '3-8 Yrs',\n",
       " '5-8 Yrs',\n",
       " '1-2 Yrs',\n",
       " '1-6 Yrs',\n",
       " '1-6 Yrs',\n",
       " '0-3 Yrs']"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_requied = [i.text for i in exp_req]\n",
    "exp_requied"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making of a Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job-title</th>\n",
       "      <th>Job-location</th>\n",
       "      <th>Company-name</th>\n",
       "      <th>Experience-required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lead - Data Analyst / Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Axim Technologies</td>\n",
       "      <td>12-14 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Schneider Electric</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Snaphunt</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BUSINESS ANALYST -DATA SCIENCE-CONSUMER</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>BRIDGEi2i Analytics Solutions Private Limited</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Jeeva Organic</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Senior Data Analyst - Supporting Audits</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Visa</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bengaluru/Bangalore</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>1-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Glance</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Glance IT Solution</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Novel Office</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Job-title         Job-location  \\\n",
       "0          Lead - Data Analyst / Scientist  Bangalore/Bengaluru   \n",
       "1                      Senior Data Analyst  Bangalore/Bengaluru   \n",
       "2                             Data Analyst  Bangalore/Bengaluru   \n",
       "3  BUSINESS ANALYST -DATA SCIENCE-CONSUMER  Bangalore/Bengaluru   \n",
       "4                             Data Analyst  Bangalore/Bengaluru   \n",
       "5  Senior Data Analyst - Supporting Audits  Bangalore/Bengaluru   \n",
       "6                             Data Analyst  Bengaluru/Bangalore   \n",
       "7                      Senior Data Analyst  Bangalore/Bengaluru   \n",
       "8                      Senior Data Analyst  Bangalore/Bengaluru   \n",
       "9                             Data Analyst  Bangalore/Bengaluru   \n",
       "\n",
       "                                    Company-name Experience-required  \n",
       "0                              Axim Technologies           12-14 Yrs  \n",
       "1                             Schneider Electric             0-2 Yrs  \n",
       "2                                       Snaphunt             0-2 Yrs  \n",
       "3  BRIDGEi2i Analytics Solutions Private Limited             0-2 Yrs  \n",
       "4                                  Jeeva Organic             3-8 Yrs  \n",
       "5                                           Visa             5-8 Yrs  \n",
       "6                                       Flipkart             1-2 Yrs  \n",
       "7                                         Glance             1-6 Yrs  \n",
       "8                             Glance IT Solution             1-6 Yrs  \n",
       "9                                   Novel Office             0-3 Yrs  "
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\"Job-title\":job_title,\"Job-location\":job_loc,\"Company-name\":company_name,\"Experience-required\":exp_requied})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location and have to scrape the job-title, job-location, company_name for first 10 jobs data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "#site url\n",
    "\n",
    "url = 'https://www.naukri.com/'\n",
    "driver.get(url)\n",
    "\n",
    "#searching an web element for job search bar using id\n",
    "search_job = driver.find_element_by_id('qsb-keyword-sugg')\n",
    "\n",
    "#now writing requied name on the search bar\n",
    "search_job.send_keys(\"Data Scientist\")\n",
    "\n",
    "#searching an web element for location search bar using absolute xpath\n",
    "search_location = driver.find_element_by_xpath(\"/html/body/div[1]/div[3]/div[2]/section/div/form/div[2]/div/div/div/div[1]/div[2]/input\")\n",
    "\n",
    "#writing \"Bangalore\" in location bar search\n",
    "search_location.send_keys(\"Bangalore\")\n",
    "\n",
    "#now for search button,we can get a web element for that using an absolute xpath\n",
    "search_button = driver.find_element_by_xpath(\"/html/body/div[1]/div[3]/div[2]/section/div/form/div[3]/button\")\n",
    "\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrapping of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a)extracting the job title\n",
    "\n",
    "#extracting the web elements which consists of job titles.\n",
    "titles_tag = driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "\n",
    "#extracting first 10 titles\n",
    "titles_tag = titles_tag[:10]\n",
    "\n",
    "#now extracting a text from those web elements\n",
    "job_title = [i.text for i in titles_tag]\n",
    "\n",
    "# b)extracting the job_location\n",
    "\n",
    "#extracting the web elements which consists of job loaction.\n",
    "loc_tag = driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "\n",
    "#extracting first 10 titles\n",
    "loc_tag = loc_tag[:10]\n",
    "\n",
    "job_loc = [i.text for i in loc_tag]\n",
    "\n",
    "# c)extracting the company name\n",
    "\n",
    "#extracting the web elements which consists of company name\n",
    "comp_tag = driver.find_elements_by_xpath('//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "\n",
    "#extracting first 10 company name\n",
    "comp_tag = comp_tag[:10]\n",
    "\n",
    "company_name = [i.text for i in comp_tag]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making of a Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job-title</th>\n",
       "      <th>Job-location</th>\n",
       "      <th>Company-name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lead/Senior Data Scientist (NLP)</td>\n",
       "      <td>Bangalore/Bengaluru\\n(WFH during Covid)</td>\n",
       "      <td>Samya.AI A FRACTAL Entity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Global Tax Automation &amp; Operations | Data Scie...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Dell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru, Mumbai ...</td>\n",
       "      <td>Fractal Analytics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lead Data Scientist - Prescriptive Analytics/P...</td>\n",
       "      <td>Hyderabad/Secunderabad, Bangalore/Bengaluru</td>\n",
       "      <td>Codersbrain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lead Data Scientist - NLP/OpenCV</td>\n",
       "      <td>Hyderabad/Secunderabad, Bangalore/Bengaluru</td>\n",
       "      <td>Codersbrain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lead - Data Analyst / Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Axim Technologies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Job opening with Wipro For Data Scientist</td>\n",
       "      <td>Hyderabad/Secunderabad, Pune, Chennai, Bangalo...</td>\n",
       "      <td>Wipro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Spark ML Data Scientist</td>\n",
       "      <td>Hyderabad/Secunderabad, Pune, Bangalore/Bengal...</td>\n",
       "      <td>Wipro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Spark ML Data Scientist</td>\n",
       "      <td>Hyderabad/Secunderabad, Pune, Bangalore/Bengaluru</td>\n",
       "      <td>Wipro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Senior Data Scientist - Logistics</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Gojek Tech</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job-title  \\\n",
       "0                   Lead/Senior Data Scientist (NLP)   \n",
       "1  Global Tax Automation & Operations | Data Scie...   \n",
       "2                              Senior Data Scientist   \n",
       "3  Lead Data Scientist - Prescriptive Analytics/P...   \n",
       "4                   Lead Data Scientist - NLP/OpenCV   \n",
       "5                    Lead - Data Analyst / Scientist   \n",
       "6          Job opening with Wipro For Data Scientist   \n",
       "7                            Spark ML Data Scientist   \n",
       "8                            Spark ML Data Scientist   \n",
       "9                  Senior Data Scientist - Logistics   \n",
       "\n",
       "                                        Job-location  \\\n",
       "0            Bangalore/Bengaluru\\n(WFH during Covid)   \n",
       "1                                Bangalore/Bengaluru   \n",
       "2  Gurgaon/Gurugram, Bangalore/Bengaluru, Mumbai ...   \n",
       "3        Hyderabad/Secunderabad, Bangalore/Bengaluru   \n",
       "4        Hyderabad/Secunderabad, Bangalore/Bengaluru   \n",
       "5                                Bangalore/Bengaluru   \n",
       "6  Hyderabad/Secunderabad, Pune, Chennai, Bangalo...   \n",
       "7  Hyderabad/Secunderabad, Pune, Bangalore/Bengal...   \n",
       "8  Hyderabad/Secunderabad, Pune, Bangalore/Bengaluru   \n",
       "9                                Bangalore/Bengaluru   \n",
       "\n",
       "                Company-name  \n",
       "0  Samya.AI A FRACTAL Entity  \n",
       "1                       Dell  \n",
       "2          Fractal Analytics  \n",
       "3                Codersbrain  \n",
       "4                Codersbrain  \n",
       "5          Axim Technologies  \n",
       "6                      Wipro  \n",
       "7                      Wipro  \n",
       "8                      Wipro  \n",
       "9                 Gojek Tech  "
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\"Job-title\":job_title,\"Job-location\":job_loc,\"Company-name\":company_name})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3) In this question have to scrape data using the filters available on the webpage\n",
    "#### =>have to use the location and salary filter.\n",
    "#### =>have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "#### =>have to scrape the job-title, job-location, company name, experience required.\n",
    "#### =>The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "#site url\n",
    "\n",
    "url = 'https://www.naukri.com/'\n",
    "driver.get(url)\n",
    "\n",
    "#searching an web element for job search bar using id\n",
    "search_job = driver.find_element_by_id('qsb-keyword-sugg')\n",
    "\n",
    "#now writing requied name on the search bar\n",
    "search_job.send_keys(\"Data Scientist\")\n",
    "\n",
    "#now for search button,we can get a web element for that using an absolute xpath\n",
    "search_button = driver.find_element_by_xpath(\"/html/body/div[1]/div[3]/div[2]/section/div/form/div[3]/button\")\n",
    "\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using filters by selecting a check boxes and using a absolute xpath to get web elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting 3-6 lakhs range salary\n",
    "sal_check = driver.find_element_by_xpath(\"/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[4]/div[2]/div[2]/label/i\")\n",
    "sal_check.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting delhi as a location\n",
    "loc_check = driver.find_element_by_xpath(\"/html/body/div[1]/div[3]/div[2]/section[1]/div[2]/div[4]/div[2]/div[3]/label/i\")\n",
    "loc_check.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrapping of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a)extracting the job title\n",
    "\n",
    "#extracting the web elements which consists of job titles.\n",
    "titles_tag = driver.find_elements_by_xpath('//a[@class=\"title fw500 ellipsis\"]')\n",
    "\n",
    "#extracting first 10 titles\n",
    "titles_tag = titles_tag[:10]\n",
    "\n",
    "#now extracting a text from those web elements\n",
    "job_title = [i.text for i in titles_tag]\n",
    "\n",
    "# b)extracting the job_location\n",
    "\n",
    "#extracting the web elements which consists of job loaction.\n",
    "loc_tag = driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "\n",
    "#extracting first 10 titles\n",
    "loc_tag = loc_tag[:10]\n",
    "\n",
    "job_loc = [i.text for i in loc_tag]\n",
    "\n",
    "# c)extracting the company name\n",
    "\n",
    "#extracting the web elements which consists of company name\n",
    "comp_tag = driver.find_elements_by_xpath('//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "\n",
    "#extracting first 10 company name\n",
    "comp_tag = comp_tag[:10]\n",
    "\n",
    "company_name = [i.text for i in comp_tag]\n",
    "\n",
    "# d)extracting the exp required\n",
    "\n",
    "#extracting the web elements which consists of experience required\n",
    "exp_req = driver.find_elements_by_xpath('//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]')\n",
    "\n",
    "#extracting first 10 \n",
    "exp_req = exp_req[:10]\n",
    "\n",
    "exp_requied = [i.text for i in exp_req]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making of a Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job-title</th>\n",
       "      <th>Job-location</th>\n",
       "      <th>Company-name</th>\n",
       "      <th>Experience-required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist | Python | Machine Learning | D...</td>\n",
       "      <td>Noida, Gurgaon/Gurugram, Delhi / NCR</td>\n",
       "      <td>Schlesinger Group</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Openings For Jr/mid/Sr level data Scientists</td>\n",
       "      <td>Kolkata, Hyderabad/Secunderabad, Pune, Ahmedab...</td>\n",
       "      <td>Pluto seven business solutions (p) limited</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Data Scientist I</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Delhivery</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist role</td>\n",
       "      <td>Noida, Hyderabad/Secunderabad, Pune, Gurgaon/G...</td>\n",
       "      <td>Mount Talent Consulting Private Limited</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist role</td>\n",
       "      <td>Noida, Hyderabad/Secunderabad, Pune, Gurgaon/G...</td>\n",
       "      <td>Mount Talent Consulting Private Limited</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Urgent Hiring For Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "      <td>Mount Talent Consulting Private Limited</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Urgent Hiring For Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "      <td>Mount Talent Consulting Private Limited</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon, Bengaluru</td>\n",
       "      <td>BlackBuck</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bharuch, Jaipur, Bhopal, Mumbai, Jhansi, Nagpu...</td>\n",
       "      <td>Country Veggie</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist Internship</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>iHackers Inc</td>\n",
       "      <td>0-1 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job-title  \\\n",
       "0  Data Scientist | Python | Machine Learning | D...   \n",
       "1       Openings For Jr/mid/Sr level data Scientists   \n",
       "2                            Senior Data Scientist I   \n",
       "3                                Data Scientist role   \n",
       "4                                Data Scientist role   \n",
       "5                   Urgent Hiring For Data Scientist   \n",
       "6                   Urgent Hiring For Data Scientist   \n",
       "7                                     Data Scientist   \n",
       "8                                     Data Scientist   \n",
       "9                          Data Scientist Internship   \n",
       "\n",
       "                                        Job-location  \\\n",
       "0               Noida, Gurgaon/Gurugram, Delhi / NCR   \n",
       "1  Kolkata, Hyderabad/Secunderabad, Pune, Ahmedab...   \n",
       "2                                   Gurgaon/Gurugram   \n",
       "3  Noida, Hyderabad/Secunderabad, Pune, Gurgaon/G...   \n",
       "4  Noida, Hyderabad/Secunderabad, Pune, Gurgaon/G...   \n",
       "5              Gurgaon/Gurugram, Bangalore/Bengaluru   \n",
       "6              Gurgaon/Gurugram, Bangalore/Bengaluru   \n",
       "7                                 Gurgaon, Bengaluru   \n",
       "8  Bharuch, Jaipur, Bhopal, Mumbai, Jhansi, Nagpu...   \n",
       "9                                          New Delhi   \n",
       "\n",
       "                                 Company-name Experience-required  \n",
       "0                           Schlesinger Group             0-3 Yrs  \n",
       "1  Pluto seven business solutions (p) limited             2-6 Yrs  \n",
       "2                                   Delhivery             3-7 Yrs  \n",
       "3     Mount Talent Consulting Private Limited             1-3 Yrs  \n",
       "4     Mount Talent Consulting Private Limited             1-3 Yrs  \n",
       "5     Mount Talent Consulting Private Limited             1-6 Yrs  \n",
       "6     Mount Talent Consulting Private Limited             1-6 Yrs  \n",
       "7                                   BlackBuck             3-7 Yrs  \n",
       "8                              Country Veggie             1-3 Yrs  \n",
       "9                                iHackers Inc             0-1 Yrs  "
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\"Job-title\":job_title,\"Job-location\":job_loc,\"Company-name\":company_name,\"Experience-required\":exp_requied})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4: Scrape data of first 100 sunglasses listings on flipkart.com and have to scrape four     attributes:1)Brand 2)Product description 3)price and 4)discount\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "#site url\n",
    "\n",
    "url = 'https://www.flipkart.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "#searching an web element for search bar using absolute xpath\n",
    "search_sunglass = driver.find_element_by_xpath('/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input')\n",
    "\n",
    "#now writing requied name on the search bar\n",
    "search_sunglass.send_keys(\"sunglasses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now for search button,we can get a web element for that using an absolute xpath\n",
    "search_button = driver.find_element_by_xpath(\"/html/body/div/div/div[1]/div[1]/div[2]/div[2]/form/div/button\")\n",
    "\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrapping of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "Brand_name,product_desc,Price,Discount = [],[],[],[]\n",
    "\n",
    "#for first page\n",
    "# a)extracting the Brand name\n",
    "\n",
    "#extracting the web elements which consists of Brand name.\n",
    "titles_tag = driver.find_elements_by_xpath('//div[@class=\"_2WkVRV\"]')\n",
    "\n",
    "Brand_name_1 = [i.text for i in titles_tag]\n",
    "   \n",
    "Brand_name += Brand_name_1\n",
    "    \n",
    "# b)extracting the Product description\n",
    "\n",
    "#extracting the web elements which consists of description.\n",
    "prod_desc = driver.find_elements_by_xpath('//a[@class=\"IRpwTa\"]')\n",
    "    \n",
    "product_desc_1 = [i.text for i in prod_desc]\n",
    "\n",
    "product_desc += product_desc_1\n",
    "\n",
    "# c)extracting the Price\n",
    "\n",
    "#extracting the web elements which consists of price.\n",
    "price_info = driver.find_elements_by_xpath('//div[@class=\"_30jeq3\"]')\n",
    "    \n",
    "Price_1 = [i.text for i in price_info]\n",
    "Price += Price_1\n",
    "\n",
    "# d)extracting the Discount\n",
    "\n",
    "#extracting the web elements which consists of discount.\n",
    "disc_info = driver.find_elements_by_xpath('//div[@class=\"_3Ay6Sb\"]')\n",
    "Discount_1 = [i.text for i in disc_info]\n",
    "\n",
    "Discount += Discount_1\n",
    "\n",
    "next_button = driver.find_element_by_xpath(\"/html/body/div/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[11]\")\n",
    "next_button.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for second page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting the web elements which consists of Brand name.\n",
    "titles_tag = driver.find_elements_by_xpath('//div[@class=\"_2WkVRV\"]')\n",
    "\n",
    "Brand_name_1 = [i.text for i in titles_tag]\n",
    "   \n",
    "Brand_name += Brand_name_1\n",
    "    \n",
    "# b)extracting the Product description\n",
    "\n",
    "#extracting the web elements which consists of description.\n",
    "prod_desc = driver.find_elements_by_xpath('//a[@class=\"IRpwTa\"]')\n",
    "    \n",
    "product_desc_1 = [i.text for i in prod_desc]\n",
    "\n",
    "product_desc += product_desc_1\n",
    "\n",
    "# c)extracting the Price\n",
    "\n",
    "#extracting the web elements which consists of price.\n",
    "price_info = driver.find_elements_by_xpath('//div[@class=\"_30jeq3\"]')\n",
    "    \n",
    "Price_1 = [i.text for i in price_info]\n",
    "Price += Price_1\n",
    "\n",
    "# d)extracting the Discount\n",
    "\n",
    "#extracting the web elements which consists of discount.\n",
    "disc_info = driver.find_elements_by_xpath('//div[@class=\"_3Ay6Sb\"]')\n",
    "Discount_1 = [i.text for i in disc_info]\n",
    "\n",
    "Discount += Discount_1\n",
    "\n",
    "next_button = driver.find_element_by_xpath(\"/html/body/div/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[12]\")\n",
    "next_button.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for third page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting the web elements which consists of Brand name.\n",
    "titles_tag = driver.find_elements_by_xpath('//div[@class=\"_2WkVRV\"]')\n",
    "\n",
    "Brand_name_1 = [i.text for i in titles_tag]\n",
    "   \n",
    "Brand_name += Brand_name_1\n",
    "    \n",
    "# b)extracting the Product description\n",
    "\n",
    "#extracting the web elements which consists of description.\n",
    "prod_desc = driver.find_elements_by_xpath('//a[@class=\"IRpwTa\"]')\n",
    "    \n",
    "product_desc_1 = [i.text for i in prod_desc]\n",
    "\n",
    "product_desc += product_desc_1\n",
    "\n",
    "# c)extracting the Price\n",
    "\n",
    "#extracting the web elements which consists of price.\n",
    "price_info = driver.find_elements_by_xpath('//div[@class=\"_30jeq3\"]')\n",
    "    \n",
    "Price_1 = [i.text for i in price_info]\n",
    "Price += Price_1\n",
    "\n",
    "# d)extracting the Discount\n",
    "\n",
    "#extracting the web elements which consists of discount.\n",
    "disc_info = driver.find_elements_by_xpath('//div[@class=\"_3Ay6Sb\"]')\n",
    "Discount_1 = [i.text for i in disc_info]\n",
    "\n",
    "Discount += Discount_1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making of a Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product-Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CRYSTAL CART</td>\n",
       "      <td>Polarized, UV Protection, Gradient, Riding Gla...</td>\n",
       "      <td>₹269</td>\n",
       "      <td>82% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Singco India</td>\n",
       "      <td>Gradient, Toughened Glass Lens, UV Protection ...</td>\n",
       "      <td>₹599</td>\n",
       "      <td>80% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SRPM</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (56)</td>\n",
       "      <td>₹188</td>\n",
       "      <td>85% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Elligator</td>\n",
       "      <td>UV Protection Round Sunglasses (54)</td>\n",
       "      <td>₹248</td>\n",
       "      <td>90% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kingsunglasses</td>\n",
       "      <td>UV Protection Round Sunglasses (54)</td>\n",
       "      <td>₹188</td>\n",
       "      <td>81% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>AISLIN</td>\n",
       "      <td>Mirrored, UV Protection Round Sunglasses (Free...</td>\n",
       "      <td>₹459</td>\n",
       "      <td>69% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection Round Sunglasses (50)</td>\n",
       "      <td>₹360</td>\n",
       "      <td>75% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Rich Club</td>\n",
       "      <td>UV Protection, Mirrored Aviator Sunglasses (Fr...</td>\n",
       "      <td>₹355</td>\n",
       "      <td>64% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>kingsunglasses</td>\n",
       "      <td>UV Protection, Gradient Retro Square Sunglasse...</td>\n",
       "      <td>₹235</td>\n",
       "      <td>87% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>ROZZETTA CRAFT</td>\n",
       "      <td>UV Protection Round Sunglasses (50)</td>\n",
       "      <td>₹349</td>\n",
       "      <td>82% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Brand                                Product-Description Price  \\\n",
       "0     CRYSTAL CART  Polarized, UV Protection, Gradient, Riding Gla...  ₹269   \n",
       "1     Singco India  Gradient, Toughened Glass Lens, UV Protection ...  ₹599   \n",
       "2             SRPM             UV Protection Wayfarer Sunglasses (56)  ₹188   \n",
       "3        Elligator                UV Protection Round Sunglasses (54)  ₹248   \n",
       "4   kingsunglasses                UV Protection Round Sunglasses (54)  ₹188   \n",
       "..             ...                                                ...   ...   \n",
       "95          AISLIN  Mirrored, UV Protection Round Sunglasses (Free...  ₹459   \n",
       "96  ROZZETTA CRAFT                UV Protection Round Sunglasses (50)  ₹360   \n",
       "97       Rich Club  UV Protection, Mirrored Aviator Sunglasses (Fr...  ₹355   \n",
       "98  kingsunglasses  UV Protection, Gradient Retro Square Sunglasse...  ₹235   \n",
       "99  ROZZETTA CRAFT                UV Protection Round Sunglasses (50)  ₹349   \n",
       "\n",
       "   Discount   \n",
       "0    82% off  \n",
       "1    80% off  \n",
       "2    85% off  \n",
       "3    90% off  \n",
       "4    81% off  \n",
       "..       ...  \n",
       "95   69% off  \n",
       "96   75% off  \n",
       "97   64% off  \n",
       "98   87% off  \n",
       "99   82% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\"Brand\":Brand_name[:100],\"Product-Description\":product_desc[:100],\"Price\":Price[:100],\"Discount \":Discount[:100] })\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5: Scrape 100 reviews data from flipkart.com for iphone11 phone.\n",
    "### have to scrape for\n",
    "### 1. Rating\n",
    "### 2. Review summary\n",
    "### 3. Full review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### since provided link is no more exist,so i will be using \n",
    "\"https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace=FLIPKART&q=iphone+11+black+64&store=tyy%2F4io&srno=s_1_2&otracker=search&otracker1=search&fm=SEARCH&iid=e92bbc94-7172-433a-aa58-bcec822e9910.MOBFKCTSVZAXUHGR.SEARCH&ppt=hp&ppn=homepage&ssid=3czdgbkxeo0000001641622092851&qH=a7bbd4f518dc07fa\" \n",
    "### this url for scrapping all required data of iphone 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "#site url\n",
    "\n",
    "url = 'https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace=FLIPKART&q=iphone+11+black+64&store=tyy%2F4io&srno=s_1_2&otracker=search&otracker1=search&fm=SEARCH&iid=e92bbc94-7172-433a-aa58-bcec822e9910.MOBFKCTSVZAXUHGR.SEARCH&ppt=hp&ppn=homepage&ssid=3czdgbkxeo0000001641622092851&qH=a7bbd4f518dc07fa'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to click on all reviews option\n",
    "\n",
    "all_reviews =driver.find_element_by_xpath(\"/html/body/div[1]/div/div[3]/div[1]/div[2]/div[9]/div/div/div[5]/div/a\")\n",
    "all_reviews.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings =  driver.find_elements_by_xpath('//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "review_sum_y = driver.find_elements_by_xpath('//p[@class=\"_2-N8zT\"]')\n",
    "full_reviews = driver.find_elements_by_xpath('//div[@class=\"t-ZTKy\"]')\n",
    "\n",
    "len(ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### so,there are 10 reviws on each page, in order get first 100 reviews data we need scrape from all 10 pages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### for page 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings =  driver.find_elements_by_xpath('//div[@class=\"col _2wzgFH K0kLPL\"]')\n",
    "review_sum_y = driver.find_elements_by_xpath('//p[@class=\"_2-N8zT\"]')\n",
    "full_reviews = driver.find_elements_by_xpath('//div[@class=\"t-ZTKy\"]')\n",
    "\n",
    "#scrapping rating\n",
    "rating1 = [((i.text).split(\"\\n\"))[0] for i in ratings]\n",
    "\n",
    "#scrapping the reviem summary\n",
    "review_sum = [i.text for i in review_sum_y]\n",
    "\n",
    "#scrapping the full-review\n",
    "full_review =[i.text for i in full_reviews]\n",
    "\n",
    "#to click next button\n",
    "next_button = driver.find_element_by_xpath('/html/body/div[1]/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[2]')\n",
    "next_button.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### for page 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings =  driver.find_elements_by_xpath('//div[@class=\"col _2wzgFH K0kLPL\"]')\n",
    "review_sum_y = driver.find_elements_by_xpath('//p[@class=\"_2-N8zT\"]')\n",
    "full_reviews = driver.find_elements_by_xpath('//div[@class=\"t-ZTKy\"]')\n",
    "\n",
    "#scrapping rating\n",
    "rating2 = [((i.text).split(\"\\n\"))[0] for i in ratings]\n",
    "\n",
    "#scrapping the reviem summary\n",
    "review_sum2 = [i.text for i in review_sum_y]\n",
    "\n",
    "#scrapping the full-review\n",
    "full_review2 =[i.text for i in full_reviews]\n",
    "\n",
    "#to click next button\n",
    "next_button = driver.find_element_by_xpath('/html/body/div[1]/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[4]')\n",
    "next_button.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### for page 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings =  driver.find_elements_by_xpath('//div[@class=\"col _2wzgFH K0kLPL\"]')\n",
    "review_sum_y = driver.find_elements_by_xpath('//p[@class=\"_2-N8zT\"]')\n",
    "full_reviews = driver.find_elements_by_xpath('//div[@class=\"t-ZTKy\"]')\n",
    "\n",
    "#scrapping rating\n",
    "rating3 = [((i.text).split(\"\\n\"))[0] for i in ratings]\n",
    "\n",
    "#scrapping the reviem summary\n",
    "review_sum3 = [i.text for i in review_sum_y]\n",
    "\n",
    "#scrapping the full-review\n",
    "full_review3 =[i.text for i in full_reviews]\n",
    "\n",
    "#to click next button\n",
    "next_button = driver.find_element_by_xpath('/html/body/div[1]/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[5]')\n",
    "next_button.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### for page 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings =  driver.find_elements_by_xpath('//div[@class=\"col _2wzgFH K0kLPL\"]')\n",
    "review_sum_y = driver.find_elements_by_xpath('//p[@class=\"_2-N8zT\"]')\n",
    "full_reviews = driver.find_elements_by_xpath('//div[@class=\"t-ZTKy\"]')\n",
    "\n",
    "#scrapping rating\n",
    "rating4 = [((i.text).split(\"\\n\"))[0] for i in ratings]\n",
    "\n",
    "#scrapping the reviem summary\n",
    "review_sum4 = [i.text for i in review_sum_y]\n",
    "\n",
    "#scrapping the full-review\n",
    "full_review4 =[i.text for i in full_reviews]\n",
    "\n",
    "#to click next button\n",
    "next_button = driver.find_element_by_xpath('/html/body/div[1]/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[6]')\n",
    "next_button.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### for page 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings =  driver.find_elements_by_xpath('//div[@class=\"col _2wzgFH K0kLPL\"]')\n",
    "review_sum_y = driver.find_elements_by_xpath('//p[@class=\"_2-N8zT\"]')\n",
    "full_reviews = driver.find_elements_by_xpath('//div[@class=\"t-ZTKy\"]')\n",
    "\n",
    "#scrapping rating\n",
    "rating5 = [((i.text).split(\"\\n\"))[0] for i in ratings]\n",
    "\n",
    "#scrapping the reviem summary\n",
    "review_sum5 = [i.text for i in review_sum_y]\n",
    "\n",
    "#scrapping the full-review\n",
    "full_review5 =[i.text for i in full_reviews]\n",
    "\n",
    "#to click next button\n",
    "next_button = driver.find_element_by_xpath('/html/body/div[1]/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[7]')\n",
    "next_button.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### for page 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings =  driver.find_elements_by_xpath('//div[@class=\"col _2wzgFH K0kLPL\"]')\n",
    "review_sum_y = driver.find_elements_by_xpath('//p[@class=\"_2-N8zT\"]')\n",
    "full_reviews = driver.find_elements_by_xpath('//div[@class=\"t-ZTKy\"]')\n",
    "\n",
    "#scrapping rating\n",
    "rating6 = [((i.text).split(\"\\n\"))[0] for i in ratings]\n",
    "\n",
    "#scrapping the reviem summary\n",
    "review_sum6 = [i.text for i in review_sum_y]\n",
    "\n",
    "#scrapping the full-review\n",
    "full_review6 =[i.text for i in full_reviews]\n",
    "\n",
    "#to click next button\n",
    "next_button = driver.find_element_by_xpath('/html/body/div[1]/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[7]')\n",
    "next_button.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### for page 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings =  driver.find_elements_by_xpath('//div[@class=\"col _2wzgFH K0kLPL\"]')\n",
    "review_sum_y = driver.find_elements_by_xpath('//p[@class=\"_2-N8zT\"]')\n",
    "full_reviews = driver.find_elements_by_xpath('//div[@class=\"t-ZTKy\"]')\n",
    "\n",
    "#scrapping rating\n",
    "rating7 = [((i.text).split(\"\\n\"))[0] for i in ratings]\n",
    "\n",
    "#scrapping the reviem summary\n",
    "review_sum7 = [i.text for i in review_sum_y]\n",
    "\n",
    "#scrapping the full-review\n",
    "full_review7 =[i.text for i in full_reviews]\n",
    "\n",
    "#to click next button\n",
    "next_button = driver.find_element_by_xpath('/html/body/div[1]/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[7]')\n",
    "next_button.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### for page 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings =  driver.find_elements_by_xpath('//div[@class=\"col _2wzgFH K0kLPL\"]')\n",
    "review_sum_y = driver.find_elements_by_xpath('//p[@class=\"_2-N8zT\"]')\n",
    "full_reviews = driver.find_elements_by_xpath('//div[@class=\"t-ZTKy\"]')\n",
    "\n",
    "#scrapping rating\n",
    "rating8 = [((i.text).split(\"\\n\"))[0] for i in ratings]\n",
    "\n",
    "#scrapping the reviem summary\n",
    "review_sum8 = [i.text for i in review_sum_y]\n",
    "\n",
    "#scrapping the full-review\n",
    "full_review8 =[i.text for i in full_reviews]\n",
    "\n",
    "#to click next button\n",
    "next_button = driver.find_element_by_xpath('/html/body/div[1]/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[7]')\n",
    "next_button.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### for page 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings =  driver.find_elements_by_xpath('//div[@class=\"col _2wzgFH K0kLPL\"]')\n",
    "review_sum_y = driver.find_elements_by_xpath('//p[@class=\"_2-N8zT\"]')\n",
    "full_reviews = driver.find_elements_by_xpath('//div[@class=\"t-ZTKy\"]')\n",
    "\n",
    "#scrapping rating\n",
    "rating9 = [((i.text).split(\"\\n\"))[0] for i in ratings]\n",
    "\n",
    "#scrapping the reviem summary\n",
    "review_sum9 = [i.text for i in review_sum_y]\n",
    "\n",
    "#scrapping the full-review\n",
    "full_review9 =[i.text for i in full_reviews]\n",
    "\n",
    "#to click next button\n",
    "next_button = driver.find_element_by_xpath('/html/body/div[1]/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[7]')\n",
    "next_button.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### for page 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings =  driver.find_elements_by_xpath('//div[@class=\"col _2wzgFH K0kLPL\"]')\n",
    "review_sum_y = driver.find_elements_by_xpath('//p[@class=\"_2-N8zT\"]')\n",
    "full_reviews = driver.find_elements_by_xpath('//div[@class=\"t-ZTKy\"]')\n",
    "\n",
    "#scrapping rating\n",
    "rating10 = [((i.text).split(\"\\n\"))[0] for i in ratings]\n",
    "\n",
    "#scrapping the reviem summary\n",
    "review_sum10 = [i.text for i in review_sum_y]\n",
    "\n",
    "#scrapping the full-review\n",
    "full_review10 =[i.text for i in full_reviews]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating = rating1 + rating2 + rating3 + rating4 + rating5 + rating6 + rating7 + rating8 + rating9 +rating10\n",
    "review_sum = review_sum + review_sum2 + review_sum3 + review_sum4 + review_sum5 + review_sum6 + review_sum7 + review_sum8 + review_sum9 + review_sum10\n",
    "full_review = full_review + full_review2 + full_review3 + full_review4 + full_review5 + full_review6 + full_review7 + full_review8 +full_review9 +full_review10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### making of a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review_summary</th>\n",
       "      <th>Full-review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Brilliant</td>\n",
       "      <td>The Best Phone for the Money\\n\\nThe iPhone 11 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Great iPhone very snappy experience as apple k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Previously I was using one plus 3t it was a gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Must buy!</td>\n",
       "      <td>Camera is excellent just lack of telephoto mod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific purchase</td>\n",
       "      <td>I use a Note10+ and have been using both iOS a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Awesome</td>\n",
       "      <td>The phone is completely good\\nAs far as camera...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>3</td>\n",
       "      <td>Decent product</td>\n",
       "      <td>Everything u ll like it when u use this iPhone...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Wonderful</td>\n",
       "      <td>Nice value for money good and best price I pho...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating       Review_summary  \\\n",
       "0       5            Brilliant   \n",
       "1       5       Simply awesome   \n",
       "2       5  Best in the market!   \n",
       "3       5     Perfect product!   \n",
       "4       5    Worth every penny   \n",
       "..    ...                  ...   \n",
       "95      5            Must buy!   \n",
       "96      5    Terrific purchase   \n",
       "97      5              Awesome   \n",
       "98      3       Decent product   \n",
       "99      5            Wonderful   \n",
       "\n",
       "                                          Full-review  \n",
       "0   The Best Phone for the Money\\n\\nThe iPhone 11 ...  \n",
       "1   Really satisfied with the Product I received.....  \n",
       "2   Great iPhone very snappy experience as apple k...  \n",
       "3   Amazing phone with great cameras and better ba...  \n",
       "4   Previously I was using one plus 3t it was a gr...  \n",
       "..                                                ...  \n",
       "95  Camera is excellent just lack of telephoto mod...  \n",
       "96  I use a Note10+ and have been using both iOS a...  \n",
       "97  The phone is completely good\\nAs far as camera...  \n",
       "98  Everything u ll like it when u use this iPhone...  \n",
       "99  Nice value for money good and best price I pho...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'Rating':rating,'Review_summary':review_sum,'Full-review':full_review})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q6: Scrape data for first 100 sneakers by entering as \"sneakers\" in search bar of flipkart.com\n",
    "### have to scrape 4 attributes of each sneaker:\n",
    "### 1. Brand\n",
    "### 2. Product Description\n",
    "### 3. Price\n",
    "### 4.Discount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [],
   "source": [
    "#site url\n",
    "\n",
    "url = 'https://www.flipkart.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "#searching an web element for search bar using absolute xpath\n",
    "search_sneakers = driver.find_element_by_xpath('/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input')\n",
    "\n",
    "#now writing requied name on the search bar\n",
    "search_sneakers.send_keys(\"sneakers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now for search button,we can get a web element for that using an absolute xpath\n",
    "search_button = driver.find_element_by_xpath(\"/html/body/div/div/div[1]/div[1]/div[2]/div[2]/form/div/button\")\n",
    "\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrapping of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "Brand_name,product_desc,Price,Discount = [],[],[],[]\n",
    "\n",
    "#since each consists of 40 items,so i will scrape 3 web pages data (to get a first 100 items)\n",
    "        \n",
    "#for first page\n",
    "# a)extracting the Brand name\n",
    "\n",
    "#extracting the web elements which consists of Brand name.\n",
    "titles_tag = driver.find_elements_by_xpath('//div[@class=\"_2WkVRV\"]')\n",
    "\n",
    "Brand_name_1 = [i.text for i in titles_tag]\n",
    "   \n",
    "Brand_name += Brand_name_1\n",
    "    \n",
    "# b)extracting the Product description and discount\n",
    "\n",
    "#extracting the web elements which consists of description and discount.\n",
    "temp = driver.find_elements_by_xpath(\"//div[@class='_2B099V']\")\n",
    "\n",
    "for i in temp:\n",
    "    i_1 = ((i.text).split(\"\\n\"))[1]\n",
    "    product_desc.append(i_1)\n",
    "    i_2 = (((i.text).split(\"%\"))[0])[-2] + (((i.text).split(\"%\"))[0])[-1] + '%' + ' off'\n",
    "    Discount.append(i_2)\n",
    "\n",
    "# c)extracting the Price\n",
    "\n",
    "#extracting the web elements which consists of price.\n",
    "price_info = driver.find_elements_by_xpath('//div[@class=\"_30jeq3\"]')\n",
    "    \n",
    "Price_1 = [i.text for i in price_info]\n",
    "Price += Price_1\n",
    "\n",
    "#clicking next button\n",
    "next_button = driver.find_element_by_xpath(\"/html/body/div/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[11]\")\n",
    "next_button.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### for second page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting the web elements which consists of Brand name.\n",
    "titles_tag = driver.find_elements_by_xpath('//div[@class=\"_2WkVRV\"]')\n",
    "\n",
    "Brand_name_1 = [i.text for i in titles_tag]\n",
    "   \n",
    "Brand_name += Brand_name_1\n",
    "    \n",
    "# b)extracting the Product description and discount\n",
    "\n",
    "#extracting the web elements which consists of description and discount.\n",
    "temp = driver.find_elements_by_xpath(\"//div[@class='_2B099V']\")\n",
    "for i in temp:\n",
    "    i_1 = ((i.text).split(\"\\n\"))[1]\n",
    "    product_desc.append(i_1)\n",
    "    i_2 = (((i.text).split(\"%\"))[0])[-2] + (((i.text).split(\"%\"))[0])[-1] + '%' + ' off'\n",
    "    Discount.append(i_2)\n",
    "\n",
    "# c)extracting the Price\n",
    "\n",
    "#extracting the web elements which consists of price.\n",
    "price_info = driver.find_elements_by_xpath('//div[@class=\"_30jeq3\"]')\n",
    "    \n",
    "Price_1 = [i.text for i in price_info]\n",
    "Price += Price_1\n",
    "\n",
    "\n",
    "next_button = driver.find_element_by_xpath(\"/html/body/div/div/div[3]/div[1]/div[2]/div[12]/div/div/nav/a[12]\")\n",
    "next_button.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### for third page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting the web elements which consists of Brand name.\n",
    "titles_tag = driver.find_elements_by_xpath('//div[@class=\"_2WkVRV\"]')\n",
    "\n",
    "Brand_name_1 = [i.text for i in titles_tag]\n",
    "   \n",
    "Brand_name += Brand_name_1\n",
    "    \n",
    "# b)extracting the Product description and discount\n",
    "\n",
    "#extracting the web elements which consists of description and discount.\n",
    "temp = driver.find_elements_by_xpath(\"//div[@class='_2B099V']\")\n",
    "for i in temp:\n",
    "    i_1 = ((i.text).split(\"\\n\"))[1]\n",
    "    product_desc.append(i_1)\n",
    "    i_2 = (((i.text).split(\"%\"))[0])[-2] + (((i.text).split(\"%\"))[0])[-1] + '%' + ' off'\n",
    "    Discount.append(i_2)\n",
    "\n",
    "\n",
    "# c)extracting the Price\n",
    "\n",
    "#extracting the web elements which consists of price.\n",
    "price_info = driver.find_elements_by_xpath('//div[@class=\"_30jeq3\"]')\n",
    "    \n",
    "Price_1 = [i.text for i in price_info]\n",
    "Price += Price_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n",
      "120\n",
      "120\n",
      "120\n"
     ]
    }
   ],
   "source": [
    "print(len(Brand_name))\n",
    "print(len(product_desc))\n",
    "print(len(Price))\n",
    "print(len(Discount))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### making of a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product-Description</th>\n",
       "      <th>Price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>luxury fashion</td>\n",
       "      <td>Luxury Fashionable casual sneaker shoes Sneake...</td>\n",
       "      <td>₹449</td>\n",
       "      <td>65% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Modern &amp; Trendy Collection Combo Pack of 02 Sh...</td>\n",
       "      <td>₹447</td>\n",
       "      <td>82% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>URBANBOX</td>\n",
       "      <td>Sneakers Sneakers For Men</td>\n",
       "      <td>₹220</td>\n",
       "      <td>77% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stefano Rads</td>\n",
       "      <td>Classy Sneakers For Men</td>\n",
       "      <td>₹242</td>\n",
       "      <td>65% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Magnolia</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹398</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>BIRDE</td>\n",
       "      <td>Combo Pack of 2 Casual Shoes Sneakers For Men</td>\n",
       "      <td>₹525</td>\n",
       "      <td>47% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Bonexy</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹474</td>\n",
       "      <td>52% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>SCATCHITE</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹398</td>\n",
       "      <td>60% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>WELDONE</td>\n",
       "      <td>Fashion Sneakers For Men</td>\n",
       "      <td>₹299</td>\n",
       "      <td>40% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>aadi</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹499</td>\n",
       "      <td>75% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Brand                                Product-Description Price  \\\n",
       "0   luxury fashion  Luxury Fashionable casual sneaker shoes Sneake...  ₹449   \n",
       "1           BRUTON  Modern & Trendy Collection Combo Pack of 02 Sh...  ₹447   \n",
       "2         URBANBOX                          Sneakers Sneakers For Men  ₹220   \n",
       "3     Stefano Rads                            Classy Sneakers For Men  ₹242   \n",
       "4         Magnolia                                   Sneakers For Men  ₹398   \n",
       "..             ...                                                ...   ...   \n",
       "95           BIRDE      Combo Pack of 2 Casual Shoes Sneakers For Men  ₹525   \n",
       "96          Bonexy                                   Sneakers For Men  ₹474   \n",
       "97       SCATCHITE                                   Sneakers For Men  ₹398   \n",
       "98         WELDONE                           Fashion Sneakers For Men  ₹299   \n",
       "99            aadi                                   Sneakers For Men  ₹499   \n",
       "\n",
       "   Discount   \n",
       "0    65% off  \n",
       "1    82% off  \n",
       "2    77% off  \n",
       "3    65% off  \n",
       "4    60% off  \n",
       "..       ...  \n",
       "95   47% off  \n",
       "96   52% off  \n",
       "97   60% off  \n",
       "98   40% off  \n",
       "99   75% off  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\"Brand\":Brand_name[:100],\"Product-Description\":product_desc[:100],\"Price\":Price[:100],\"Discount \":Discount[:100] })\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q7: From the link - https://www.myntra.com/shoes Setting Price filter to “Rs. 7149 to Rs. 14099” , Color filter to “Black” and then scrape First 100 shoes data you get. The data should include “Brand” of the shoes , 'Shoe description' and 'price' of the shoe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "#site url\n",
    "\n",
    "url = 'https://www.myntra.com/shoes'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using filters by selecting a check boxes and using a absolute xpath to get web elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting colour as \"Black\"\n",
    "\n",
    "black_color_check = driver.find_element_by_xpath('/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[6]/ul/li[1]/label/div')\n",
    "black_color_check.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selecting price-range of \"Rs. 7189(7209) to Rs. 14099(14139)\"\n",
    "\n",
    "price_check = driver.find_element_by_xpath(\"/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[5]/ul/li[2]/label/div\")\n",
    "price_check.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting a data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "Brand_name,shoe_desc,Price = [],[],[]\n",
    "\n",
    "#since each consists of 50 items,so i will scrape 2 web pages data (to get a first 100 items)\n",
    "        \n",
    "#for first page\n",
    "# a)extracting the Brand name\n",
    "\n",
    "#extracting the web elements which consists of Brand name.\n",
    "titles_tag = driver.find_elements_by_xpath('//h3[@class=\"product-brand\"]')\n",
    "Brand_name_1 = [i.text for i in titles_tag]\n",
    "   \n",
    "Brand_name += Brand_name_1\n",
    "\n",
    "# b)extracting the shoe description\n",
    "\n",
    "#extracting the web elements which consists of description.\n",
    "sh_desc = driver.find_elements_by_xpath('//h4[@class=\"product-product\"]')\n",
    "sh_des = [i.text for i in sh_desc]\n",
    "\n",
    "shoe_desc += sh_des\n",
    "\n",
    "# c)extracting the price of shoe\n",
    "\n",
    "#extracting the web elements which consists of price.\n",
    "price_info = driver.find_elements_by_xpath('//div[@class=\"product-price\"]')\n",
    "Price_i = [\"Rs\" +((i.text).split(\"Rs\"))[1] for i in price_info]\n",
    "\n",
    "Price += Price_i\n",
    "\n",
    "#Clicking next button\n",
    "\n",
    "next_button = driver.find_element_by_xpath(\"/html/body/div[2]/div/div[1]/main/div[3]/div[2]/div/div[2]/section/div[2]/ul/li[12]/a\")\n",
    "next_button.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### for second page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting the web elements which consists of Brand name.\n",
    "titles_tag = driver.find_elements_by_xpath('//h3[@class=\"product-brand\"]')\n",
    "Brand_name_1 = [i.text for i in titles_tag]\n",
    "   \n",
    "Brand_name += Brand_name_1\n",
    "\n",
    "# b)extracting the shoe description\n",
    "\n",
    "#extracting the web elements which consists of description.\n",
    "sh_desc = driver.find_elements_by_xpath('//h4[@class=\"product-product\"]')\n",
    "sh_des = [i.text for i in sh_desc]\n",
    "\n",
    "shoe_desc += sh_des\n",
    "\n",
    "# c)extracting the price of shoe\n",
    "\n",
    "#extracting the web elements which consists of price.\n",
    "price_info = driver.find_elements_by_xpath('//div[@class=\"product-price\"]')\n",
    "Price_i = [\"Rs\" +((i.text).split(\"Rs\"))[1] for i in price_info]\n",
    "\n",
    "Price += Price_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(Brand_name),len(shoe_desc),len(Price))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### making of a Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand name</th>\n",
       "      <th>Shoe-Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Men Running Shoes</td>\n",
       "      <td>Rs. 8449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Men Magnify Nitro Running</td>\n",
       "      <td>Rs. 8449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Saint G</td>\n",
       "      <td>Men Mid-Top Chelsea Boots</td>\n",
       "      <td>Rs. 9810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RARE RABBIT</td>\n",
       "      <td>Men Leather Flat Boots</td>\n",
       "      <td>Rs. 7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Saint G</td>\n",
       "      <td>Women Leather Heeled Boots</td>\n",
       "      <td>Rs. 13410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>J.FONTINI</td>\n",
       "      <td>Men Solid Loafers</td>\n",
       "      <td>Rs. 8990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Ruosh</td>\n",
       "      <td>Men Solid Leather Formal Monks</td>\n",
       "      <td>Rs. 8990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>MANGO</td>\n",
       "      <td>Textured High-Top Flat Boots</td>\n",
       "      <td>Rs. 7990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Bugatti</td>\n",
       "      <td>Leather Block Heeled Boots</td>\n",
       "      <td>Rs. 7999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Geox</td>\n",
       "      <td>Women Leather High-Top Flat Boots</td>\n",
       "      <td>Rs. 12599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Brand name                   Shoe-Description      Price\n",
       "0          Puma                  Men Running Shoes   Rs. 8449\n",
       "1          Puma          Men Magnify Nitro Running   Rs. 8449\n",
       "2       Saint G          Men Mid-Top Chelsea Boots   Rs. 9810\n",
       "3   RARE RABBIT             Men Leather Flat Boots   Rs. 7999\n",
       "4       Saint G         Women Leather Heeled Boots  Rs. 13410\n",
       "..          ...                                ...        ...\n",
       "95    J.FONTINI                  Men Solid Loafers   Rs. 8990\n",
       "96        Ruosh     Men Solid Leather Formal Monks   Rs. 8990\n",
       "97        MANGO       Textured High-Top Flat Boots   Rs. 7990\n",
       "98      Bugatti         Leather Block Heeled Boots   Rs. 7999\n",
       "99         Geox  Women Leather High-Top Flat Boots  Rs. 12599\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 502,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\"Brand name\":Brand_name,\"Shoe-Description\":shoe_desc,\"Price\":Price})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q8: From the webpage https://www.amazon.in/  Searching for a \"Laptop\" and setting a filters for CPU Type to “Intel Core i7” and “Intel Core i9\" have to scrape first 10 laptops data.\n",
    "#### And have to scrape 3 attributes for each laptop: \"Title\",\"Ratings\" and \"Price\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 792,
   "metadata": {},
   "outputs": [],
   "source": [
    "#site url\n",
    "\n",
    "url = 'https://www.amazon.in/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 793,
   "metadata": {},
   "outputs": [],
   "source": [
    "#searching an web element for search bar using xpath\n",
    "search_laptop = driver.find_element_by_xpath('/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[2]/div[1]/input')\n",
    "\n",
    "#now writing requied name on the search bar\n",
    "search_laptop.send_keys(\"Laptop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 794,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now for search button,we can get a web element for that using an absolute xpath\n",
    "search_button = driver.find_element_by_xpath(\"/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[3]/div/span/input\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### While Applying filters,we dont have a choice of selecting both core i7 and  core i9  at a same time,so will scrape data for each filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 795,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting CPU type to \"Intel Core i7\"\n",
    "\n",
    "i7_check = driver.find_element_by_xpath('/html/body/div[1]/div[2]/div[1]/div[2]/div/div[3]/span/div[1]/span/div/div/div[7]/ul[1]/li[10]/span/a/div/label/i')\n",
    "i7_check.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrapping of data for core i7 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 796,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 796,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#extracting the web elements which consists of titles.\n",
    "titles_tag1 = driver.find_elements_by_xpath('//span[@class=\"a-size-medium a-color-base a-text-normal\"]')\n",
    "title = [i.text for i in titles_tag1][:10]\n",
    "len(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 797,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 797,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extracting the web elements which consists of price.\n",
    "price_tag = driver.find_elements_by_xpath('//div[@class=\"a-row a-size-base a-color-base\"]')\n",
    "price = [((i.text).split(\"\\n\"))[0] for i in price_tag][:10]\n",
    "len(price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 798,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting the web elements which consists of Ratings.\n",
    "ratings7 = []\n",
    "#extracting for each product\n",
    "\n",
    "# for 1st product\n",
    "ratings2_tem = driver.find_element_by_xpath('/html/body/div[1]/div[2]/div[1]/div[1]/div/span[3]/div[2]/div[2]/div/span/div/div/div[2]/div[2]/div/div/div[2]/div/span[1]/span/a/i[2]')\n",
    "ratings2_tem.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 802,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings2_tem1 = driver.find_elements_by_xpath('//span[@class=\"a-size-medium a-color-base a-text-beside-button a-text-bold\"]')\n",
    "l = [i.text for i in ratings2_tem1][0]\n",
    "\n",
    "ratings7.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 803,
   "metadata": {},
   "outputs": [],
   "source": [
    "move_over = driver.find_element_by_xpath(\"/html/body/div[1]/div[2]/span/div/span/h1/div/div[1]/div/div\")\n",
    "move_over.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 804,
   "metadata": {},
   "outputs": [],
   "source": [
    "#since there is no record on ratings for 2nd model, so will fill with \"NA\"\n",
    "ratings9.append(\"NA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 805,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for 3rd product\n",
    "ratings2_tem = driver.find_element_by_xpath('/html/body/div[1]/div[2]/div[1]/div[1]/div/span[3]/div[2]/div[4]/div/span/div/div/div[2]/div[2]/div/div/div[2]/div/span[1]/span/a/i[2]')\n",
    "ratings2_tem.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 808,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings2_tem1 = driver.find_elements_by_xpath('//span[@class=\"a-size-medium a-color-base a-text-beside-button a-text-bold\"]')\n",
    "l = [i.text for i in ratings2_tem1][1]\n",
    "ratings7.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 810,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4.6 out of 5', '4.7 out of 5']"
      ]
     },
     "execution_count": 810,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "move_over = driver.find_element_by_xpath(\"/html/body/div[1]/div[2]/span/div/span/h1/div/div[1]/div/div\")\n",
    "move_over.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 811,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for 4th product\n",
    "ratings2_tem = driver.find_element_by_xpath('/html/body/div[1]/div[2]/div[1]/div[1]/div/span[3]/div[2]/div[5]/div/span/div/div/div[2]/div[2]/div/div/div[2]/div/span[1]/span/a/i[2]')\n",
    "ratings2_tem.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 815,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings2_tem1 = driver.find_elements_by_xpath('//span[@class=\"a-size-medium a-color-base a-text-beside-button a-text-bold\"]')\n",
    "l = [i.text for i in ratings2_tem1][2]\n",
    "\n",
    "ratings7.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 816,
   "metadata": {},
   "outputs": [],
   "source": [
    "move_over.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 817,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for 5th product\n",
    "ratings2_tem = driver.find_element_by_xpath('/html/body/div[1]/div[2]/div[1]/div[1]/div/span[3]/div[2]/div[6]/div/span/div/div/div[2]/div[2]/div/div/div[2]/div/span[1]/span/a/i[2]')\n",
    "ratings2_tem.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 821,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings2_tem1 = driver.find_elements_by_xpath('//span[@class=\"a-size-medium a-color-base a-text-beside-button a-text-bold\"]')\n",
    "l = [i.text for i in ratings2_tem1][3]\n",
    "\n",
    "ratings7.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 822,
   "metadata": {},
   "outputs": [],
   "source": [
    "move_over.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 823,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for 6th product\n",
    "ratings2_tem = driver.find_element_by_xpath('/html/body/div[1]/div[2]/div[1]/div[1]/div/span[3]/div[2]/div[7]/div/span/div/div/div[2]/div[2]/div/div/div[2]/div/span[1]/span/a/i[2]')\n",
    "ratings2_tem.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 826,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings2_tem1 = driver.find_elements_by_xpath('//span[@class=\"a-size-medium a-color-base a-text-beside-button a-text-bold\"]')\n",
    "l = [i.text for i in ratings2_tem1][4]\n",
    "\n",
    "ratings7.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 827,
   "metadata": {},
   "outputs": [],
   "source": [
    "move_over.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 828,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for 7th product\n",
    "ratings2_tem = driver.find_element_by_xpath('/html/body/div[1]/div[2]/div[1]/div[1]/div/span[3]/div[2]/div[2]/div/span/div/div/div[2]/div[2]/div/div/div[2]/div/span[1]/span/a/i[2]')\n",
    "ratings2_tem.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 832,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings2_tem1 = driver.find_elements_by_xpath('//span[@class=\"a-size-medium a-color-base a-text-beside-button a-text-bold\"]')\n",
    "l = [i.text for i in ratings2_tem1][0]\n",
    "\n",
    "ratings7.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 833,
   "metadata": {},
   "outputs": [],
   "source": [
    "move_over.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for 8th product\n",
    "ratings2_tem = driver.find_element_by_xpath('/html/body/div[1]/div[2]/div[1]/div[1]/div/span[3]/div[2]/div[9]/div/span/div/div/div[2]/div[2]/div/div/div[2]/div/span[1]/span/a/i[2]')\n",
    "ratings2_tem.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 837,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings2_tem1 = driver.find_elements_by_xpath('//span[@class=\"a-size-medium a-color-base a-text-beside-button a-text-bold\"]')\n",
    "l = [i.text for i in ratings2_tem1][-1]\n",
    "\n",
    "ratings7.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 838,
   "metadata": {},
   "outputs": [],
   "source": [
    "move_over.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for 9th product\n",
    "ratings2_tem = driver.find_element_by_xpath('/html/body/div[1]/div[2]/div[1]/div[1]/div/span[3]/div[2]/div[10]/div/span/div/div/div[2]/div[2]/div/div/div[2]/div/span[1]/span/a/i[2]')\n",
    "ratings2_tem.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 842,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings2_tem1 = driver.find_elements_by_xpath('//span[@class=\"a-size-medium a-color-base a-text-beside-button a-text-bold\"]')\n",
    "l = [i.text for i in ratings2_tem1][-1]\n",
    "\n",
    "ratings7.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 843,
   "metadata": {},
   "outputs": [],
   "source": [
    "move_over.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 844,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for 10th product\n",
    "ratings2_tem = driver.find_element_by_xpath('/html/body/div[1]/div[2]/div[1]/div[1]/div/span[3]/div[2]/div[2]/div/span/div/div/div[2]/div[2]/div/div/div[2]/div/span[1]/span/a/i[2]')\n",
    "ratings2_tem.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 847,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings2_tem1 = driver.find_elements_by_xpath('//span[@class=\"a-size-medium a-color-base a-text-beside-button a-text-bold\"]')\n",
    "l = [i.text for i in ratings2_tem1][0]\n",
    "\n",
    "ratings7.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 860,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings7.insert(1,\"NA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 862,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(title),len(ratings7),len(price))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### making a dataframe for intel core i7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 863,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acer Nitro 5 AN515-57 Gaming Laptop | Intel Co...</td>\n",
       "      <td>4.6 out of 5</td>\n",
       "      <td>₹89,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASUS VivoBook 14 (2021), 14-inch (35.56 cms) F...</td>\n",
       "      <td>NA</td>\n",
       "      <td>₹59,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASUS TUF Gaming F15 (2021) 15.6-inch (39.62 cm...</td>\n",
       "      <td>4.7 out of 5</td>\n",
       "      <td>₹1,14,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lenovo ThinkBook 13s Intel 11th Gen Core i7 13...</td>\n",
       "      <td>4.3 out of 5</td>\n",
       "      <td>₹99,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASUS TUF Dash F15 (2021), 15.6-inch (39.62 cms...</td>\n",
       "      <td>4 out of 5</td>\n",
       "      <td>₹82,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LG Gram 17-inches Ultra-Light Intel Evo 11th G...</td>\n",
       "      <td>4.6 out of 5</td>\n",
       "      <td>₹99,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HP Pavilion 13, 11th Gen Intel Core i7, 13.3-i...</td>\n",
       "      <td>4.6 out of 5</td>\n",
       "      <td>₹86,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Mi Notebook Horizon Edition 14 Intel Core i7-1...</td>\n",
       "      <td>4.2 out of 5</td>\n",
       "      <td>₹57,790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lenovo Legion 5 11th Gen Intel Core i7 15.6\"(3...</td>\n",
       "      <td>4.3 out of 5</td>\n",
       "      <td>₹1,00,490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ASUS TUF Dash F15 (2021), 15.6\" (39.62 cms) FH...</td>\n",
       "      <td>4.6 out of 5</td>\n",
       "      <td>₹95,990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title        Rating      Price\n",
       "0  Acer Nitro 5 AN515-57 Gaming Laptop | Intel Co...  4.6 out of 5    ₹89,990\n",
       "1  ASUS VivoBook 14 (2021), 14-inch (35.56 cms) F...            NA    ₹59,990\n",
       "2  ASUS TUF Gaming F15 (2021) 15.6-inch (39.62 cm...  4.7 out of 5  ₹1,14,990\n",
       "3  Lenovo ThinkBook 13s Intel 11th Gen Core i7 13...  4.3 out of 5    ₹99,990\n",
       "4  ASUS TUF Dash F15 (2021), 15.6-inch (39.62 cms...    4 out of 5    ₹82,990\n",
       "5  LG Gram 17-inches Ultra-Light Intel Evo 11th G...  4.6 out of 5    ₹99,990\n",
       "6  HP Pavilion 13, 11th Gen Intel Core i7, 13.3-i...  4.6 out of 5    ₹86,990\n",
       "7  Mi Notebook Horizon Edition 14 Intel Core i7-1...  4.2 out of 5    ₹57,790\n",
       "8  Lenovo Legion 5 11th Gen Intel Core i7 15.6\"(3...  4.3 out of 5  ₹1,00,490\n",
       "9  ASUS TUF Dash F15 (2021), 15.6\" (39.62 cms) FH...  4.6 out of 5    ₹95,990"
      ]
     },
     "execution_count": 863,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_i7 = pd.DataFrame({\"Title\":title,\"Rating\":ratings7,\"Price\":price})\n",
    "df_i7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrapping of data for core i9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to clear filter\n",
    "clear_filter = driver.find_element_by_xpath(\"/html/body/div[1]/div[2]/div[1]/div[2]/div/div[3]/span/div[1]/span/div/div/div[7]/ul[1]/li[1]/span/a/span[2]\")\n",
    "clear_filter.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting CPU type to \"Intel Core i9\"\n",
    "\n",
    "i7_check = driver.find_element_by_xpath('/html/body/div[1]/div[2]/div[1]/div[2]/div/div[3]/span/div[1]/span/div/div/div[7]/ul[1]/li[11]/span/a/div/label/i')\n",
    "i7_check.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 675,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extracting the web elements which consists of titles.\n",
    "titles_tag2 = driver.find_elements_by_xpath('//span[@class=\"a-size-medium a-color-base a-text-normal\"]')\n",
    "title_9 = [i.text for i in titles_tag2][:10]\n",
    "len(title_9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting the web elements which consists of price.\n",
    "price_tag2 = driver.find_elements_by_xpath('//span[@class=\"a-price-whole\"]')\n",
    "price_9 = [(i.text) for i in price_tag2][:9]\n",
    "\n",
    "#since there is no price tag for 9th item,so will repalce with \"NA\"\n",
    "price_9.insert(8,\"NA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### #extracting the web elements which consists of Ratings for each item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings9 = []\n",
    "# for 1st product\n",
    "ratings2_tem = driver.find_element_by_xpath('/html/body/div[1]/div[2]/div[1]/div[1]/div/span[3]/div[2]/div[2]/div/span/div/div/div[2]/div[2]/div/div/div[2]/div/span[1]/span/a/i[2]')\n",
    "ratings2_tem.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 773,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings2_tem1 = driver.find_elements_by_xpath('//span[@class=\"a-size-medium a-color-base a-text-beside-button a-text-bold\"]')\n",
    "l = [i.text for i in ratings2_tem1][1]\n",
    "ratings9.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 774,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for 2nd item\n",
    "ratings2_tem = driver.find_element_by_xpath('/html/body/div[1]/div[2]/div[1]/div[1]/div/span[3]/div[2]/div[3]/div/span/div/div/div[2]/div[2]/div/div/div[2]/div/span[1]/span/a/i[2]')\n",
    "ratings2_tem.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 775,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings2_tem1 = driver.find_elements_by_xpath('//span[@class=\"a-size-medium a-color-base a-text-beside-button a-text-bold\"]')\n",
    "l = [i.text for i in ratings2_tem1][0]\n",
    "ratings9.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 776,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for 3rd item\n",
    "ratings2_tem = driver.find_element_by_xpath('/html/body/div[1]/div[2]/div[1]/div[1]/div/span[3]/div[2]/div[4]/div/span/div/div/div[2]/div[2]/div/div/div[2]/div/span[1]/span/a/i[2]')\n",
    "ratings2_tem.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 782,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4.1 out of 5', '4 out of 5', '4.4 out of 5']"
      ]
     },
     "execution_count": 782,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings2_tem1 = driver.find_elements_by_xpath('//span[@class=\"a-size-medium a-color-base a-text-beside-button a-text-bold\"]')\n",
    "l = [i.text for i in ratings2_tem1][2]\n",
    "# ratings9.append(l)\n",
    "del ratings9[-1]\n",
    "ratings9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 783,
   "metadata": {},
   "outputs": [],
   "source": [
    "#since there is no record on ratings for 4th and 5th model, so will fill with \"NA\"\n",
    "ratings9.append(\"NA\")\n",
    "ratings9.append(\"NA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 784,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for 6th item\n",
    "ratings2_tem = driver.find_element_by_xpath('/html/body/div[1]/div[2]/div[1]/div[1]/div/span[3]/div[2]/div[7]/div/span/div/div/div[2]/div[2]/div/div/div[2]/div/span[1]/span/a/i[2]')\n",
    "ratings2_tem.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 785,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings2_tem1 = driver.find_elements_by_xpath('//span[@class=\"a-size-medium a-color-base a-text-beside-button a-text-bold\"]')\n",
    "l = [i.text for i in ratings2_tem1][3]\n",
    "ratings9.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "metadata": {},
   "outputs": [],
   "source": [
    "#since there is no record on ratings for 7th model, so will fill with \"NA\"\n",
    "ratings9.append(\"NA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 787,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for 8th item\n",
    "ratings2_tem = driver.find_element_by_xpath('/html/body/div[1]/div[2]/div[1]/div[1]/div/span[3]/div[2]/div[9]/div/span/div/div/div[2]/div[2]/div/div/div[2]/div/span[1]/span/a/i[2]')\n",
    "ratings2_tem.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 788,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings2_tem1 = driver.find_elements_by_xpath('//span[@class=\"a-size-medium a-color-base a-text-beside-button a-text-bold\"]')\n",
    "l = [i.text for i in ratings2_tem1][4]\n",
    "\n",
    "ratings9.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 789,
   "metadata": {},
   "outputs": [],
   "source": [
    "#since there is no record on ratings for 9th and 10th model, so will fill with \"NA\"\n",
    "ratings9.append(\"NA\")\n",
    "ratings9.append(\"NA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 790,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(ratings9),len(price_9),len(title_9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### making a dataframe for intel core i9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 791,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ASUS TUF Gaming F15 (2021), 15.6\" (39.62 cms) ...</td>\n",
       "      <td>4.1 out of 5</td>\n",
       "      <td>1,44,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASUS TUF Gaming F15 (2021), 15.6-inch (39.62 c...</td>\n",
       "      <td>4 out of 5</td>\n",
       "      <td>1,41,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lenovo Legion 7 10th Gen Intel Core i9 15.6 in...</td>\n",
       "      <td>4.4 out of 5</td>\n",
       "      <td>2,65,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dell XPS 17 (2021) i9-11900H Touch Screen Lapt...</td>\n",
       "      <td>NA</td>\n",
       "      <td>3,25,500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HP ZBOOK Power G8/ Intel core i9-11900H 8 Core...</td>\n",
       "      <td>NA</td>\n",
       "      <td>2,45,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ASUS TUF Gaming F15 (2021), 15.6-inch (39.62 c...</td>\n",
       "      <td>5 out of 5</td>\n",
       "      <td>1,39,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Dell Precision 5550 || i9 -10885H || 16GB || 1...</td>\n",
       "      <td>NA</td>\n",
       "      <td>2,00,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Dell G7 7500 15.6inch FHD 300 Hz Display Gamin...</td>\n",
       "      <td>4.1 out of 5</td>\n",
       "      <td>2,05,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(Renewed) Dell G7 7500 15.6inch FHD 300 Hz Dis...</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Z2 G5 Workstation 700W /Core i9-10900 (2.8GHz ...</td>\n",
       "      <td>NA</td>\n",
       "      <td>2,39,000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title        Rating     Price\n",
       "0  ASUS TUF Gaming F15 (2021), 15.6\" (39.62 cms) ...  4.1 out of 5  1,44,990\n",
       "1  ASUS TUF Gaming F15 (2021), 15.6-inch (39.62 c...    4 out of 5  1,41,990\n",
       "2  Lenovo Legion 7 10th Gen Intel Core i9 15.6 in...  4.4 out of 5  2,65,999\n",
       "3  Dell XPS 17 (2021) i9-11900H Touch Screen Lapt...            NA  3,25,500\n",
       "4  HP ZBOOK Power G8/ Intel core i9-11900H 8 Core...            NA  2,45,000\n",
       "5  ASUS TUF Gaming F15 (2021), 15.6-inch (39.62 c...    5 out of 5  1,39,990\n",
       "6  Dell Precision 5550 || i9 -10885H || 16GB || 1...            NA  2,00,000\n",
       "7  Dell G7 7500 15.6inch FHD 300 Hz Display Gamin...  4.1 out of 5  2,05,990\n",
       "8  (Renewed) Dell G7 7500 15.6inch FHD 300 Hz Dis...            NA        NA\n",
       "9  Z2 G5 Workstation 700W /Core i9-10900 (2.8GHz ...            NA  2,39,000"
      ]
     },
     "execution_count": 791,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_i9 = pd.DataFrame({\"Title\":title_9,\"Rating\":ratings9,\"Price\":price_9})\n",
    "df_i9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q9: Write a python program to scrape data for first 10 job results for Data Scientist Designation in Noida location. You have to scrape company name, No. of days ago when job was posted, Rating of the company from  https://www.ambitionbox.com/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {},
   "outputs": [],
   "source": [
    "#site url\n",
    "url = 'https://www.ambitionbox.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now for jobs button,we can get a web element for that using an absolute xpath\n",
    "jobs_button = driver.find_element_by_xpath(\"/html/body/div[1]/nav/nav/a[6]\")\n",
    "jobs_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entering as a \"Data Scientist\" is search bar\n",
    "\n",
    "jobs_search = driver.find_element_by_xpath(\"/html/body/div/div/div/div[2]/div[1]/div/div/div/div/span/input\")\n",
    "jobs_search.send_keys(\"Data Scientist\")\n",
    "\n",
    "#searching jobs for this role\n",
    "\n",
    "search_button = driver.find_element_by_xpath(\"/html/body/div/div/div/div[2]/div[1]/div/div/div/button\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selectin a location option \n",
    "\n",
    "click_loc =  driver.find_element_by_xpath(\"/html/body/div/div/div/div[2]/div[2]/div[1]/div/div/div/div[2]/div[1]/i\")\n",
    "click_loc.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [],
   "source": [
    "#entering as a Noida in location search bar\n",
    "\n",
    "enter_loc =  driver.find_element_by_xpath(\"/html/body/div/div/div/div[2]/div[2]/div[1]/div/div/div/div[2]/div[2]/div/div[2]/input\")\n",
    "enter_loc.send_keys(\"Noida\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [],
   "source": [
    "selec_loc =  driver.find_element_by_xpath(\"/html/body/div/div/div/div[2]/div[2]/div[1]/div/div/div/div[2]/div[2]/div/div[3]/div[1]/div[1]/div/label\")\n",
    "selec_loc.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrapping of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting the first 10 jobs data\n",
    "\n",
    "#extracting the company name using absolute xpath\n",
    "comp_name = driver.find_elements_by_xpath('//div[@class=\"company-info\"]')\n",
    "company_n = [((i.text).split(\"\\n\"))[0] for i in comp_name]\n",
    "del company_n[0]\n",
    "\n",
    "#extracting the rating using absolute xpath\n",
    "\n",
    "rating_s = driver.find_elements_by_xpath('//div[@class=\"rating-wrapper\"]')\n",
    "rating = [((i.text).split(\"\\n\"))[0] for i in rating_s]\n",
    "del rating[0:4]\n",
    "\n",
    "#extracting the job_posted time using absolute xpath\n",
    "\n",
    "time_ago = driver.find_elements_by_xpath('//span[@class=\"body-small-l\"]')\n",
    "Job_posted_ago = [(i.text) for i in time_ago]\n",
    "Job_posted_ago_n = [Job_posted_ago[i] for i in range(0,len(Job_posted_ago),2)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(company_n),len(rating),len(Job_posted_ago_n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comapany name</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Posted ago</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nokia Solutions and Networks India (P)Ltd.</td>\n",
       "      <td>4.3</td>\n",
       "      <td>8d ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LG Electronics India Pvt. Ltd.</td>\n",
       "      <td>4.1</td>\n",
       "      <td>29d ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Paytm</td>\n",
       "      <td>3.7</td>\n",
       "      <td>2d ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jubilant Foodworks Limited</td>\n",
       "      <td>3.9</td>\n",
       "      <td>19d ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CHT Sapiense</td>\n",
       "      <td>3.7</td>\n",
       "      <td>3d ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CHT Sapiense</td>\n",
       "      <td>3.7</td>\n",
       "      <td>4d ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GI Group</td>\n",
       "      <td>4.1</td>\n",
       "      <td>15d ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GI Group</td>\n",
       "      <td>4.1</td>\n",
       "      <td>15d ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GI Group</td>\n",
       "      <td>4.1</td>\n",
       "      <td>15d ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Paytm</td>\n",
       "      <td>3.7</td>\n",
       "      <td>23d ago</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Comapany name Rating Posted ago\n",
       "0  Nokia Solutions and Networks India (P)Ltd.    4.3     8d ago\n",
       "1              LG Electronics India Pvt. Ltd.    4.1    29d ago\n",
       "2                                       Paytm    3.7     2d ago\n",
       "3                  Jubilant Foodworks Limited    3.9    19d ago\n",
       "4                                CHT Sapiense    3.7     3d ago\n",
       "5                                CHT Sapiense    3.7     4d ago\n",
       "6                                    GI Group    4.1    15d ago\n",
       "7                                    GI Group    4.1    15d ago\n",
       "8                                    GI Group    4.1    15d ago\n",
       "9                                       Paytm    3.7    23d ago"
      ]
     },
     "execution_count": 593,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\"Comapany name\":company_n,\"Rating\":rating,\"Posted ago\":Job_posted_ago_n})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q10: Write a python program to scrape the salary data for Data Scientist designation.You have to scrape Company name, Number of salaries, Average salary, Minsalary, Max Salary for first 10 companies from  https://www.ambitionbox.com/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [],
   "source": [
    "#site url\n",
    "url = 'https://www.ambitionbox.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now for salaries option button,we can get a web element for that using an absolute xpath\n",
    "jobs_button = driver.find_element_by_xpath(\"/html/body/div[1]/nav/nav/a[4]\")\n",
    "jobs_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entering as a \"Data Scientist\" is search bar\n",
    "\n",
    "jobs_search = driver.find_element_by_xpath(\"/html/body/div/div/div/main/section[1]/div[2]/div[1]/span/input\")\n",
    "jobs_search.send_keys(\"Data Scientist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_button = driver.find_element_by_xpath(\"/html/body/div/div/div/main/section[1]/div[2]/div[1]/span/div/div/div[1]\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrapping of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracting the first 10 jobs data\n",
    "\n",
    "#extracting the company name and no.of salaries using absolute xpath\n",
    "comp_info = driver.find_elements_by_xpath('//div[@class=\"name\"]')\n",
    "company_n = [((i.text).split(\"\\n\"))[0] for i in comp_info]\n",
    "no_of_salaries = [((i.text).split(\"\\n\"))[1] for i in comp_info]\n",
    "\n",
    "#extracting the experience required using absolute xpath\n",
    "exp_req = driver.find_elements_by_xpath('//div[@class=\"salaries sbold-list-header\"]')\n",
    "experience_req = [((i.text).split(\"\\n\"))[-1] for i in exp_req]\n",
    "\n",
    "#extracting the minimum,maximum and average salary using absolute xpath\n",
    "min_max_avg_sal = driver.find_elements_by_xpath('//div[@class=\"salary-range-wrapper\"]')\n",
    "minimum_sal = [((i.text).split(\"\\n\"))[1] for i in min_max_avg_sal]\n",
    "max_sal = [((i.text).split(\"\\n\"))[-1] for i in min_max_avg_sal]\n",
    "Avg_sal = [((i.text).split(\"\\n\"))[0] for i in min_max_avg_sal]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### making a Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comapany name</th>\n",
       "      <th>no. of salaries</th>\n",
       "      <th>Experience required</th>\n",
       "      <th>minimum salary</th>\n",
       "      <th>Average salary</th>\n",
       "      <th>maximum salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Walmart</td>\n",
       "      <td>based on 10 salaries</td>\n",
       "      <td>3 yrs exp</td>\n",
       "      <td>₹ 17.7L</td>\n",
       "      <td>₹ 28.7L</td>\n",
       "      <td>₹ 35.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ab Inbev</td>\n",
       "      <td>based on 22 salaries</td>\n",
       "      <td>3-4 yrs exp</td>\n",
       "      <td>₹ 15.0L</td>\n",
       "      <td>₹ 19.5L</td>\n",
       "      <td>₹ 25.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ZS</td>\n",
       "      <td>based on 14 salaries</td>\n",
       "      <td>2 yrs exp</td>\n",
       "      <td>₹ 9.8L</td>\n",
       "      <td>₹ 15.8L</td>\n",
       "      <td>₹ 20.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>based on 72 salaries</td>\n",
       "      <td>2-4 yrs exp</td>\n",
       "      <td>₹ 9.5L</td>\n",
       "      <td>₹ 15.0L</td>\n",
       "      <td>₹ 22.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Optum</td>\n",
       "      <td>based on 23 salaries</td>\n",
       "      <td>3-4 yrs exp</td>\n",
       "      <td>₹ 11.0L</td>\n",
       "      <td>₹ 15.0L</td>\n",
       "      <td>₹ 21.3L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UnitedHealth</td>\n",
       "      <td>based on 49 salaries</td>\n",
       "      <td>2-4 yrs exp</td>\n",
       "      <td>₹ 7.2L</td>\n",
       "      <td>₹ 13.5L</td>\n",
       "      <td>₹ 20.5L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tiger Analytics</td>\n",
       "      <td>based on 27 salaries</td>\n",
       "      <td>3-4 yrs exp</td>\n",
       "      <td>₹ 8.3L</td>\n",
       "      <td>₹ 13.5L</td>\n",
       "      <td>₹ 18.5L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Verizon</td>\n",
       "      <td>based on 14 salaries</td>\n",
       "      <td>4 yrs exp</td>\n",
       "      <td>₹ 10.0L</td>\n",
       "      <td>₹ 12.7L</td>\n",
       "      <td>₹ 21.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ganit Business Solutions</td>\n",
       "      <td>based on 13 salaries</td>\n",
       "      <td>4 yrs exp</td>\n",
       "      <td>₹ 8.5L</td>\n",
       "      <td>₹ 12.4L</td>\n",
       "      <td>₹ 15.0L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ericsson</td>\n",
       "      <td>based on 42 salaries</td>\n",
       "      <td>3-4 yrs exp</td>\n",
       "      <td>₹ 5.8L</td>\n",
       "      <td>₹ 11.9L</td>\n",
       "      <td>₹ 21.5L</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Comapany name       no. of salaries Experience required  \\\n",
       "0                   Walmart  based on 10 salaries           3 yrs exp   \n",
       "1                  Ab Inbev  based on 22 salaries         3-4 yrs exp   \n",
       "2                        ZS  based on 14 salaries           2 yrs exp   \n",
       "3         Fractal Analytics  based on 72 salaries         2-4 yrs exp   \n",
       "4                     Optum  based on 23 salaries         3-4 yrs exp   \n",
       "5              UnitedHealth  based on 49 salaries         2-4 yrs exp   \n",
       "6           Tiger Analytics  based on 27 salaries         3-4 yrs exp   \n",
       "7                   Verizon  based on 14 salaries           4 yrs exp   \n",
       "8  Ganit Business Solutions  based on 13 salaries           4 yrs exp   \n",
       "9                  Ericsson  based on 42 salaries         3-4 yrs exp   \n",
       "\n",
       "  minimum salary Average salary maximum salary  \n",
       "0        ₹ 17.7L        ₹ 28.7L        ₹ 35.0L  \n",
       "1        ₹ 15.0L        ₹ 19.5L        ₹ 25.0L  \n",
       "2         ₹ 9.8L        ₹ 15.8L        ₹ 20.0L  \n",
       "3         ₹ 9.5L        ₹ 15.0L        ₹ 22.0L  \n",
       "4        ₹ 11.0L        ₹ 15.0L        ₹ 21.3L  \n",
       "5         ₹ 7.2L        ₹ 13.5L        ₹ 20.5L  \n",
       "6         ₹ 8.3L        ₹ 13.5L        ₹ 18.5L  \n",
       "7        ₹ 10.0L        ₹ 12.7L        ₹ 21.0L  \n",
       "8         ₹ 8.5L        ₹ 12.4L        ₹ 15.0L  \n",
       "9         ₹ 5.8L        ₹ 11.9L        ₹ 21.5L  "
      ]
     },
     "execution_count": 611,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\"Comapany name\":company_n,\"no. of salaries\":no_of_salaries,\"Experience required\":experience_req,\n",
    "                   \"minimum salary\":minimum_sal,\"Average salary\":Avg_sal,\"maximum salary\":max_sal})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#                           ----------------------------END----------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
